{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"bytsizebio \u00b6 We aim to make short and simple bioinformatics tutorials. Get involved \u00b6 suggest a tutorial","title":"Home"},{"location":"#bytsizebio","text":"We aim to make short and simple bioinformatics tutorials.","title":"bytsizebio"},{"location":"#get-involved","text":"suggest a tutorial","title":"Get involved"},{"location":"tutorials/","text":".ipynb notebooks here will be converted to .md files (along with their images) and placed in the tutorials/docs/tutorials folder","title":"Index"},{"location":"tutorials/Introduction_single_cell_RNA_seq/","text":"An introduction to single-cell RNA-seq \u00b6 Written by Sina Booeshaghi and Lior Pachter . Based on material taught in Caltech course Bi/BE/CS183 by Lior Pachter and Matt Thomson, with contributions from Sina Booeshaghi, Lambda Lu, Jialong Jiang, Eduardo Beltrame, Jase Gehring, Ingileif Hallgr\u00edmsd\u00f3ttir and Valentine Svensson. \u00b6 *Division of Biology and Biological Engineering, California Institute of Technology \u00b6 The rapid development of single-cell genomics methods starting in 2009 has created unprecedented opportunity for highly resolved measurements of cellular states. Among such methods, single-cell RNA-seq (scRNA-seq) is having a profound impact on biology. Here we introduce some of the key concepts of single-cell RNA-seq technologies, with a focus on droplet based methods. To learn how to pre-process and analyze single-cell RNA-seq explore the following Google Colab notebooks that explain how to go from reads to results: Pre-processing and quality control [ Python , R ] Getting started with analysis [ Python , R ] Building and annotating an atlas [ Python , R ] The kallistobus.tools tutorials site has a extensive list of tutorials and vignettes on single-cell RNA-seq. Setup \u00b6 This notebook is a \"living document\". It downloads data and performs computations. As such it requires the installation of some python packages, which are installed with the commands below. In addition to running on Google Colab, the notebook can be downloaded and run locally on any machine which has python3 installed. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 #@title Install packages %%capture !pip install matplotlib !pip install scikit-learn !pip install numpy !pip install scipy !pip install anndata import numpy as np import matplotlib.cm as cm import matplotlib.pyplot as plt import matplotlib.colors as mplcol import matplotlib.font_manager import matplotlib as mpl import pandas as pd import io import anndata from scipy.stats import binom from scipy.stats import poisson from scipy.sparse import csr_matrix from scipy.io import mmread from sklearn import linear_model from IPython.display import HTML from mizani.breaks import date_breaks from mizani.formatters import date_format # Only pandas >= v0.25.0 supports column names with spaces in querys import plotnine as p import requests import warnings import colorsys warnings.filterwarnings(\"ignore\") # plotnine has a lot of MatplotlibDeprecationWarning's import seaborn as sns sns.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 2.5}) fsize=20 plt.rcParams.update({'font.size': fsize}) %config InlineBackend.figure_format = 'retina' Motivation \u00b6 The goal of single-cell transcriptomics is to measure the transcriptional states of large numbers of cells simultaneously. The input to a scRNA-seq method is a collection of cells, possibly from intact tissue, or in dissociated form. Formally, the desired output is a transcripts x cells or genes x cells matrix that describes, for each cell, the abundance of its constituent transcripts or genes. More generally, single-cell genomics methods seek to measure not just transcriptional state, but other modalities in cells, e.g. protein abundances, epigenetic states, cellular morphology, etc. The ideal single-cell technology should thus: Be universal in terms of cell size, type and state. Perform in situ measurements. Have no minimum input requirements. Assay every cell, i.e. have a 100% capture rate . Detect every transcript in every cell, i.e. have 100% sensitivity . Identify individual transcripts by their full-length sequence . Assign transcripts correctly to cells, e.g. no doublets . Be compatible with additional multimodal measurements . Be cost effective per cell. Be easy to use . Be open source so that it is transparent, and results from it reproducible. There is no method satisfying all of these requirements, however progress has been rapid. The development of single-cell RNA-seq technologies and their adoption by biologists, has been remarkable. Svensson et al. 2019 describes a database of articles which present single-cell RNA-seq experiments, and the graph below, rendered from the current version of the database , makes clear the exponential growth in single-cell transcriptomics: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 #@title Growth of single-cell RNA-seq df = pd.read_csv('http://nxn.se/single-cell-studies/data.tsv', sep='\\t') # converts string to date format, can only be run once! df['Date'] = pd.to_datetime(df['Date'], format='%Y%m%d') # converts string of reported cells total to float, can only be run once! df['Reported cells total'] = df['Reported cells total'].str.replace(',', '').map(float) # plot number of studies over time fig, ax = plt.subplots(figsize=(12, 5)) papers = pd.read_csv('http://nxn.se/single-cell-studies/data.tsv', sep='\\t') papers['Datetime'] = pd.to_datetime(papers['Date'], format='%Y%m%d') papers = papers.sort_values(\"Date\") papers[\"count\"] = 1 x = papers.Datetime y = papers[\"count\"].groupby(papers.Datetime.dt.time).cumsum() ax.plot(x, y, color=\"k\") ax.set_xlabel(\"Date\") ax.set_ylabel(\"Cumulative number of studies\") plt.show() There are many different scRNA-seq technologies in use and under development, but broadly they fall into a few categories - well-based methods (e.g. Fluidigm SMARTer C1, Smart-seq2) - droplet-based methods (e.g. Drop-seq, InDrops, 10X Genomics Chromium) - spatial transcriptomics approaches (e.g. MERFISH, SEQFISH) At the time of initial writing of this document (2019), droplet-based approaches have become popular due to their relative low-cost, easy of use, and scalability. This is evident in a breakdown of articles by technology used: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 #@title Technologies used def tidy_split(df, column, sep='|', keep=False): indexes = list() new_values = list() df = df.dropna(subset=[column]) for i, presplit in enumerate(df[column].astype(str)): values = presplit.split(sep) if keep and len(values) > 1: indexes.append(i) new_values.append(presplit) for value in values: indexes.append(i) new_values.append(value) new_df = df.iloc[indexes, :].copy() new_df[column] = new_values return new_df ts = pd.Timestamp tdf = tidy_split(df, 'Technique', ' & ') t_dict = {k: k for k in tdf['Technique'].value_counts().head(5).index} tdf['Technique'] = tdf['Technique'].map(lambda s: t_dict.get(s, 'Other')) techs = list( tdf['Technique'] .value_counts() .sort_index() .index .difference(['Other']) ) techs.append('Other') tdf['Technique'] = ( pd.Categorical( tdf['Technique'], categories=techs, ordered=True ) ) def desaturate(color, prop): # Check inputs # if not 0 <= prop <= 1: # raise ValueError(\"prop must be between 0 and 1\") # Get rgb tuple rep rgb = mplcol.colorConverter.to_rgb(color) # Convert to hls h, l, s = colorsys.rgb_to_hls(*rgb) # Desaturate the saturation channel # l *= prop l = 0.8 # Convert back to rgb new_color = colorsys.hls_to_rgb(h, l, s) hex_color = '#{:02x}{:02x}{:02x}'.format(*map(lambda c: int(c * 255), new_color)) return hex_color # lighten matplotlib default colors clrs = list(map(lambda c: desaturate(c, 1.2), ['C0', 'C1', 'C2', 'C3', 'C4', 'black'])) #### Plot number of studies per month by technique per_month = ( tdf .groupby('Technique') .resample('1M', on='Date') .count()['DOI'] .reset_index() ) p.options.figure_size = (9, 2) fig = ( p.ggplot( p.aes(x='Date', y='DOI', fill='Technique'), data=per_month.query('Date > @ts(\"20130101T010101\")') ) + p.geom_bar(stat='identity', color='grey') + p.theme_minimal(base_family='DejaVu Sans') + p.scale_x_datetime( breaks=date_breaks('1 years'), labels=date_format('%Y') ) + p.labs(y='Number of studies') + p.scale_fill_manual(clrs) ) fig <ggplot: (-9223363288449985206)> We therefore restrict this exposition to droplet-based technologies. Droplet-based methods \u00b6 Droplet based single-cell RNA-seq methods were popularized by a pair of papers published concurrently in 2015: - Macosko et al., Highly parallel genome-wide expression profiling of individual cells using nanoliter droplets , 2015. DOI:10.1016/j.cell.2015.05.002 - describes Drop-seq. - Klein et al., Droplet barcoding for single-cell transcriptomics applied to embryonic stem cells , 2015. DOI:10.1016/j.cell.2015.04.044 - descibes inDrops. Both of the methods makes use of developments in microfluidics published in: - Song, Chen, Ismagilov, Reactions in droplets in microfluidic channels , 2006. DOI:10.1002/anie.200601554 - Guo, Rotem, Heyman and Weitz, Droplet microfluidics for high-throughput biological assays , 2012. DOI:10.1039/C2LC21147E Overview \u00b6 An overview of how a droplet based scRNA-seq method works is illustrated in a figure from the Drop-seq Macosko et al. 2015 paper: A microfluidic device is used to generate an emulsion, which consists of aqueous droplets in oil. The droplets are used to encapsulate cells, beads and reagents. In other words, each droplet is a \"mini laboratory\" in which the RNA from a single-cell can be captured and prepared for identification. Thus, the consistuent parts are as follows: an emulsion (white circles containing beads and cells on the right hand-side of the figure). dissociated cells (depicted as odd-shaped colored objects in the figure). beads (flowing in from the left hand side of the figure). Emulsions \u00b6 The foundation of droplet based single-cell RNA-seq methods are mono-dispersed emulsions . Mono-dispersed refers to the requirements that droplets are of (near) uniform size. Mono-dispersed emulsions can be generated with a microfluidic device, as shown below. The droplets are being \"pinched off\" at the junction, and one can see a polystyrene bead being captured in one droplet, while others are empty. The movie is from the McCarolll Drop-seq tutorial courtesy of Patrick Stumpf, Matthew Rose-Zerilli, Rosanna Smith, Martin Fischlechner & Jonathan West at the Centre for Hybrid Biodevices & Cancer Sciences Unit at the University of Southampton. Beads \u00b6 The figure above, reproduce from Klein et al. 2015, shows the procedure used to make hydrogel beads for inDrops. Every bead contains the same barcode sequence, while the barcode sequences on two different beads are distinct. The barcode and UMI structure for a variety of technologies is viewable in a compilation by Xi Chen. Single cell suspensions \u00b6 In order to assay the transcriptomes of individual cells with droplet-based single-cell RNA-seq technologies, it is necessary to first dissociate tissue. Procedures for tissue dissociation are varied, and highly dependent on the organism, type of tissue, and many other factors. Protocols may be be enzymatic, but can also utilize mechanical dissociators. The talk below provides an introduction to tissue handling and dissociation. 1 2 3 #@title Tissue handling and dissociation from IPython.display import HTML HTML('<iframe width=\"882\" height=\"496\" src=\"https://www.youtube.com/embed/ARozvI4AbS8\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>') Statistics of beads & cells in droplets \u00b6 The binomial distribution \u00b6 An understanding of droplet-based single-cell RNA-seq requires consideration of the statistics describing the capture of cells and beads in droplets. Suppose that in an experiment multiple droplets have been formed, and focus on one of the droplets. Assume that the probability that any single one of $n$ cells were captured inside it is $p$. We can calculate the probability that $k$ cells have been captured in the droplet as follows: $$ \\mathbb{P}({\\mbox Droplet\\ contains\\ k\\ cells}) = \\binom{n}{k}p^k(1-p)^{n-k}.$$ The expected number of cells in the droplet is $$\\lambda := \\sum_{k=0}^n k \\binom{n}{k}p^k(1-p)^{n-k} = n \\cdot p.$$ We plot this distribution on number of cells in a droplet below. It is called the Binomial distribution and has two parameters: $n$ and $p$. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 #@title Binomial distribution { run: \"auto\" } n = 10#@param {type:\"integer\"} p = 0.02 #@param {type:\"slider\", min:0, max:1, step:0.01} fig, ax = plt.subplots(figsize=(7, 4)) s = 10 x = np.arange(s) y = binom.pmf(x,n,p) ax.bar(x, y, color=\"k\", label=\"Binomial n, p = ({}, {})\".format(n,p)) ax.set_xlabel(\"Number of Trials\") ax.set_ylabel(\"Probability\") ax.set_xticks(x) ax.legend() plt.show() With $n=10$ and $p=0.02$, it's quite probable that the droplet is empty, and while possible that it contains one cell, unlikely that it has 2 or more. This is a good regime for a single-cell experiment; we will see that it is problematic if two cells are captured in a single droplet. Empty droplets are not problematic in the sense that they will not lead to data, and can therefore be ignored. The Poisson distribution \u00b6 The Binomial distribution can be difficult to work with in practice. Suppose, for example, that $n=1000$ and $p=0.002$. Suppose that we are interested in the probability of seeing 431 cells in a droplet. This probability is given by $$\\binom{1000}{421}0.02^{421}(1-0.02)^{1000-431},$$ which is evidently a difficult number to calculate exactly. A practical alternative to the binmomial is the Poisson distribution. The Poisson distribution has one parameter, and its support is the non-negative integers. A random variable $X$ is Poisson distributed if $$\\mathbb{P}(X=k)\\quad = \\quad \\frac{e^{-\\lambda}\\lambda^k}{k!}.$$ The Poisson limit theorem states that if $p_n$ is a sequence of real numbers in $[0,1]$ with the sequence $np_n$ converging to to a finite limit $\\lambda$, then $${\\mbox lim}_{n \\rightarrow \\infty} \\binom{n}{k}p_n^{k}(1-p_n)^{n-k} = e^{-\\lambda}\\frac{\\lambda^k}{k!}.$$ Thus, the Poisson distribution serves as a useful, tractable distribution to work with in lieu of the Binomial distribution for large $n$ and small $p$. The histogram below can be used to explore the Poisson and its relationship to the binomial 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 #@title Binomial - Poisson comparison { run: \"auto\" } n = 10#@param {type:\"integer\"} p = 0.02 #@param {type:\"slider\", min:0, max:1, step:0.01} s = 10 lambda_param = n*p fig, ax = plt.subplots(figsize=(14, 4), ncols=2) x = np.arange(s) y = poisson.pmf(x, lambda_param) ax[0].bar(x, y, color=\"k\", label=\"Binomial n, p = ({}, {})\".format(n,p)) ax[0].set_xlabel(\"Number of Trials\") ax[0].set_ylabel(\"Probability\") ax[0].set_xticks(x) ax[0].legend() x = np.arange(s) y = binom.pmf(x,n,p) ax[1].bar(x, y, color=\"k\", label=\"Poisson $\\lambda$={}\".format(lambda_param)) ax[1].set_xlabel(\"Number of Trials\") ax[1].set_ylabel(\"Probability\") ax[1].set_xticks(x) ax[1].legend() plt.show() We therefore posit that $$ \\mathbb{P}({\\mbox Droplet\\ contains\\ k\\ cells}) = \\frac{e^{-\\lambda}\\lambda^k}{k!}$$ and $$ \\mathbb{P}({\\mbox Droplet\\ contains\\ j\\ beads}) = \\frac{e^{-\\mu}\\mu^j}{j!}.$$ Droplet tuning \u00b6 Cell capture and bead overload \u00b6 The cell capture rate is the probability that a droplet has at least one bead, and is given by $1-e^{-\\mu}$. The bead overload rate is the rate at which captured single cells are associated with two or more different barcodes, which will happen when multiple beads are loaded into a droplet with one cell. The probability this happens is $$\\frac{1-e^{-\\mu}-\\mu e^{-\\mu}}{1-e^{-\\mu}}.$$ This leads to a tradeoff, as shown below. 1 2 3 4 5 6 7 8 9 10 11 12 13 #@title Tradeoff { run: \"auto\" } fig, ax = plt.subplots(figsize=(5,5)) mu = np.arange(0, 10, 0.1) x = 1 - np.exp(-mu) y = (1 - np.exp(-mu)-mu*np.exp(-mu))/(1-np.exp(-mu)) ax.plot(x, y, color='k') ax.set_xlabel(\"Cell capture rate\") ax.set_ylabel(\"Bead overload rate\") plt.show() Sub-Poisson loading \u00b6 In order to circumvent the limit posed by a Poisson process for beads in droplets, the inDrops method uses tightly packed hydrogel beads that can be injected into droplets without loss. This approach, which leads to \" sub-Poisson loading \" is also used by 10X Genomics, and allows for increased capture rate. The difference is shown in two videos from the Abate lab linked to below. The first video, shows beads loaded being loaded in droplets with Poisson statistics: 1 2 #@title Poisson loading HTML('<iframe width=\"688\" height=\"387\" src=\"https://www.youtube.com/embed/usK71SG30t0?autoplay=1&loop=1&playlist=usK71SG30t0\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>') The next video shows sub-Poisson loading with hydrogel beads. In this case the flow rate has been set so that exactly two beads are situated in each droplet. 1 2 #@title Sub-Poisson loading { run: \"auto\" } HTML('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/2q1Lt9DWmRQ?autoplay=1&loop=1&playlist=2q1Lt9DWmRQ\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>') The following shows the types of beads used for different droplet-based scRNA-seq methods, and associated properties: Property Drop-seq inDrops 10x genomics Bead material Polystyrene Hydrogel Hydrogel Loading dynamics Poisson sub-Poisson sub-Poisson Dissolvable No No Yes Barcode release No UV release Chemical release Customizable Demonstrated Not shown Feasible Licensing Open source Open Source Proprietary Availability Beads are sold Commercial Commercial Barcode collisions \u00b6 Barcode collisions arise when two cells are separately encapsulated with beads that happen to contain identical barcodes. For $n$ assayed cells with $m$ barcodes, the barcode collision rate is the expected proportion of assayed cells that did not receive a unique barcode, i.e. $$1-\\frac{\\mathbb{E}[\\mbox{cells with a unique barcode}]}{\\mbox{number of cells}}$$ $$= 1-(1-\\frac{1}{m})^{n-1} \\approx 1-\\left(\\frac{1}{e}\\right)^\\frac{n}{m}.$$ Avoiding barcode collisions requires high barcode diversity, i.e. a small ratio of $\\frac{n}{m}$. 1 2 3 4 5 6 7 8 9 10 11 12 13 #@title Diversity and collisions { run: \"auto\" } fig, ax = plt.subplots(figsize=(5,5)) bc = np.arange(0, 1, 0.01) x = bc y = 1 - np.exp(-bc) ax.plot(x, y, color='k') ax.set_xlabel(\"n/m\") ax.set_ylabel(\"Barcode collision rate\") plt.show() Barcode diversity and length \u00b6 A 1% barcode collision rate requires a barcode diversity of ~1%, i.e. the number of barcodes should be 100 times the number of cells. The number of barcodes from a sequence of length $L$ is $4^L$. Therefore, to assay $n$ cells, the barcode sequence must be of length at least $log_4n+3\\frac{1}{3}$. This is a minimum and does not account for the need to be robust to sequencing errors. Technical doublets \u00b6 Technical doublets arise when two or more cells are captured in a droplet with a single bead. The technical doublet rate is therefore the probability of capturing two or more cells in a droplet given that at least one cell has been captured in a droplet: $\\frac{1-e^{-\\lambda}-\\lambda e^{-\\lambda}}{1-e^{-\\lambda}}$. Note that \"overloading\" a droplet-based single-cell experiment by loading more cells while keeping flow rates constant will increase the number of technical doublets due to an effective increase in $\\lambda$ and also the number of synthetic doublets due to an increase in barcode diversity. The barnyard plot \u00b6 Technical doublet rates can be measured by experiments in which a mixture of cells from two different species are assayed together. For example, if mouse and human cells are pooled prior to single-cell RNA-seq, the resultant reads ought to be assignable to either human or mouse. If a droplet contained a \"mixed\" doublet, i.e. two cells one of which is from human and the other from mouse, it will generate reads some of which can be aligned to mouse, and some to human. An example from a 10X Genomics dataset ( 5k 1:1 mixture of fresh frozen human (HEK293T) and mouse (NIH3T3) cells ) is shown in the plot below, which is called a Barnyard plot in Macosko et al. 2015 . 1 2 3 4 %%capture # Download a matrix of human and mouse !wget http://cf.10xgenomics.com/samples/cell-exp/3.0.0/hgmm_1k_v2/hgmm_1k_v2_filtered_feature_bc_matrix.tar.gz !tar -xvf hgmm_1k_v2_filtered_feature_bc_matrix.tar.gz 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 #@title Human & mouse PBMCs mtx = csr_matrix(mmread(\"/content/filtered_feature_bc_matrix/matrix.mtx.gz\").T) genes = pd.read_csv(\"/content/filtered_feature_bc_matrix/features.tsv.gz\", header=None, names=[\"gene_id\", \"gene_name\", \"extra\"], sep=\"\\t\") cells = pd.read_csv(\"/content/filtered_feature_bc_matrix/barcodes.tsv.gz\", header=None, names=[\"cell_barcode\"], sep=\"\\t\") adata = anndata.AnnData(X=mtx, var=genes, obs=cells) adata.var[\"human\"] = adata.var[\"gene_id\"].str.contains(\"hg19\").values x = (mtx[:,adata.var[\"human\"].values]).sum(axis=1) y = (mtx[:,~adata.var[\"human\"].values]).sum(axis=1) fig, ax = plt.subplots(figsize=(5,5)) x = np.asarray(x).reshape(-1) y = np.asarray(y).reshape(-1) ax.scatter(x, y, color='k') ax.set_xlabel(\"Human UMI counts per cell\") ax.set_ylabel(\"Mouse UMI counts per cell\") ax.xaxis.set_major_formatter(mpl.ticker.StrMethodFormatter('{x:,.0f}')) ax.yaxis.set_major_formatter(mpl.ticker.StrMethodFormatter('{x:,.0f}')) plt.show() THe plot shows that there are only 7 doublets out of 5,000 cells in this experiment. This is an unusually small number and atypical of most experiments, where doublet rates are between 5%--15% (see DePasquale et al. 2018 ); perhaps the 5k human mouse PBMC dataset data is articularly \"clean\" as it is an advertisement distributed by 10X Genomics. Bloom's correction \u00b6 The 7 doublets identifiable by eye in the plot above are all mixed doublets , i.e. they contain one human and one mouse cell. However doublets may consist of two mouse cells, or two human cells. If the number of droplets containing at least one human cells is $n_1$, the number containing at least one mouse cell is $n_2$, and the number of mixed doublets is $n_{1,2}$, then an estimate for the actual doublet rate can be obtained from the calculation below ( Bloom 2018 ): Given $n_1, n_2$ and $n_{1,2}$ as described above (note that $n_1$ is the number of cells on the x axis + the number of mixed doublets and $n_2$ is the number of cells on the y axis + the number of mixed doublets), then in expectation $$\\frac{n_1}{N} \\cdot \\frac{n_2}{N} = \\frac{n_{1,2}}{N}, $$ where $N$ is the total number of droplets. From this we see that $$ \\hat{N} = \\frac{n_1 \\cdot n_2}{n_{1,2}}.$$ This is the maximum likelihood Lincoln-Petersen estimator for population size from mark and recapture. Let $\\mu_1$ nad $\\mu_2$ be the Poisson rates for the respective types of cells, i.e. the average number of cells of each type per droplet. Then $$ \\hat{\\mu}_1 = -\\mbox{ln } \\left( \\frac{N-n_1}{N} \\right)$$ and $$ \\hat{\\mu}_2 = -\\mbox{ln } \\left( \\frac{N-n_2}{N} \\right).$$ From this the doublet rate $D$ can be estimated as $$\\hat{D} = 1 - \\frac{(\\mu_1+\\mu_2)e^{-\\mu_1+\\mu_2}}{1-e^{-\\mu_1-\\mu_2}}.$$ Biological doublets \u00b6 Biological doublets arise when two cells form a discrete unit that does not break apart during disruption to form a single-cell suspension. Note that biological doublets cannot be detected in barnyard plots. One approach to avoiding biological doublets is to perform single-nuclei RNA-seq. See, e.g. Habib et al., 2017 . However, biological doublets are not necessarily just a technical artifact to be avoided. Halpern et al., 2018 utilizes biological doublets of hepatocytes and liver endothelial cells to assign tissue coordinates to liver endothelial cells via imputation from their hepatocyte partners. Unique Molecular Identifiers \u00b6 The number of distinct UMIs on a bead in a droplet is at most $4^L$ where $L$ is the number of UMI bases. For example, for 10X Genomics v2 technology $L=10$ and for 10X Genomics v3 technology $L=12$. Melsted, Booeshaghi et al. 2019 show how to estimate the number of the actual distinct UMIs on each bead for which data is obtained in a scRNA-seq experiment. Summary \u00b6 Selection of a single-cell RNA-seq method requires choosing among many tradeoffs that reflect the underlying technologies. The table below, from From Zhang et al. 2019. DOI:10.1016/j.molcel.2018.10.020 , summarizes the three most popular droplet-based single-cell RNA-seq assays: The generation of single-cell RNA-seq data is just the first step in understanding the transcriptomes cells. To interpret the data reads must be aligned or pseudoaligned, UMIs counted, and large cell x gene matrices examined. The growth in single-cell RNA-seq analysis tools for these tasks has been breathtaking. The graph below, plotted from real-time data downloaded from the scRNA-seq tools database , shows the number of tools published since 2016. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 #@title Growth of single-cell tools { run: \"auto\" } tools = pd.read_csv('https://raw.githubusercontent.com/Oshlack/scRNA-tools/master/database/tools.tsv', sep='\\t') tools[\"Datetime\"] = pd.to_datetime(tools[\"Added\"]) tools = tools.sort_values(\"Added\") tools[\"count\"] = 1 fig, ax = plt.subplots(figsize=(12, 5)) x = tools.Datetime y = tools[\"count\"].groupby(tools.Datetime.dt.time).cumsum() ax.plot(x, y, color=\"k\") ax.set_xlabel(\"Date\") ax.set_ylabel(\"Number of tools\") ax.tick_params(axis='x', rotation=45) plt.show() In fact, the rate of growth of single-cell RNA-seq tools is similar to that of single-cell RNA-seq studies : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 #@title scRNA-seq tools vs. studies linear regression date_papers = papers.groupby(\"Datetime\")[\"count\"].sum() date_tools = tools.groupby(\"Datetime\")[\"count\"].sum() dates = pd.date_range(start='7/26/2002', end='01/01/2025') combined = pd.DataFrame(index=dates) combined[\"tool_counts\"] = combined.index.map(date_tools) combined[\"paper_counts\"] = combined.index.map(date_papers) combined = combined.fillna(0) combined[\"Datetime\"] = combined.index.values fig, ax = plt.subplots(figsize=(5,5)) x = combined[\"paper_counts\"].groupby(combined.Datetime.dt.time).cumsum() y = combined[\"tool_counts\"].groupby(combined.Datetime.dt.time).cumsum() ax.scatter(x, y, color=\"k\") regr = linear_model.LinearRegression() x = x.values[:, np.newaxis] regr.fit(x, y.values) xx = np.linspace(0, max(x), 200) yy = regr.intercept_ + regr.coef_*xx ax.plot(xx, yy, color=\"r\", label=f\"{regr.intercept_:,.2f} + {regr.coef_[0]:,.2f}*x\") lims = [np.min([ax.get_xlim(), ax.get_ylim()]), # min of both axes np.max([ax.get_xlim(), ax.get_ylim()])] # max of both axes ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0) ax.set_aspect('equal') ax.set_xlim(lims) ax.set_ylim(lims) ax.set_xlabel(\"Cumulative Papers\") ax.set_ylabel(\"Cumulative Tools\") ax.legend() plt.show() Next step: to learn how to analyze single-cell RNA-seq data, visit the kallistobus.tools site tutorials site and explore the \"Introduction 1: pre-processing and quality control\" notebook in Python or R . Feedback : please report any issues, or submit pull requests for improvements, in the Github repository where this notebook is located .","title":"Introduction single cell RNA seq"},{"location":"tutorials/Introduction_single_cell_RNA_seq/#an-introduction-to-single-cell-rna-seq","text":"","title":"An introduction to single-cell RNA-seq"},{"location":"tutorials/Introduction_single_cell_RNA_seq/#written-by-sina-booeshaghi-and-lior-pachter-based-on-material-taught-in-caltech-course-bibecs183-by-lior-pachter-and-matt-thomson-with-contributions-from-sina-booeshaghi-lambda-lu-jialong-jiang-eduardo-beltrame-jase-gehring-ingileif-hallgrimsdottir-and-valentine-svensson","text":"","title":"Written by Sina Booeshaghi and Lior Pachter. Based on material taught in Caltech course Bi/BE/CS183 by Lior Pachter and Matt Thomson, with contributions from Sina Booeshaghi, Lambda Lu, Jialong Jiang, Eduardo Beltrame, Jase Gehring, Ingileif Hallgr\u00edmsd\u00f3ttir and Valentine Svensson."},{"location":"tutorials/Introduction_single_cell_RNA_seq/#division-of-biology-and-biological-engineering-california-institute-of-technology","text":"The rapid development of single-cell genomics methods starting in 2009 has created unprecedented opportunity for highly resolved measurements of cellular states. Among such methods, single-cell RNA-seq (scRNA-seq) is having a profound impact on biology. Here we introduce some of the key concepts of single-cell RNA-seq technologies, with a focus on droplet based methods. To learn how to pre-process and analyze single-cell RNA-seq explore the following Google Colab notebooks that explain how to go from reads to results: Pre-processing and quality control [ Python , R ] Getting started with analysis [ Python , R ] Building and annotating an atlas [ Python , R ] The kallistobus.tools tutorials site has a extensive list of tutorials and vignettes on single-cell RNA-seq.","title":"*Division of Biology and Biological Engineering, California Institute of Technology"},{"location":"tutorials/Introduction_single_cell_RNA_seq/#setup","text":"This notebook is a \"living document\". It downloads data and performs computations. As such it requires the installation of some python packages, which are installed with the commands below. In addition to running on Google Colab, the notebook can be downloaded and run locally on any machine which has python3 installed. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 #@title Install packages %%capture !pip install matplotlib !pip install scikit-learn !pip install numpy !pip install scipy !pip install anndata import numpy as np import matplotlib.cm as cm import matplotlib.pyplot as plt import matplotlib.colors as mplcol import matplotlib.font_manager import matplotlib as mpl import pandas as pd import io import anndata from scipy.stats import binom from scipy.stats import poisson from scipy.sparse import csr_matrix from scipy.io import mmread from sklearn import linear_model from IPython.display import HTML from mizani.breaks import date_breaks from mizani.formatters import date_format # Only pandas >= v0.25.0 supports column names with spaces in querys import plotnine as p import requests import warnings import colorsys warnings.filterwarnings(\"ignore\") # plotnine has a lot of MatplotlibDeprecationWarning's import seaborn as sns sns.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 2.5}) fsize=20 plt.rcParams.update({'font.size': fsize}) %config InlineBackend.figure_format = 'retina'","title":"Setup"},{"location":"tutorials/Introduction_single_cell_RNA_seq/#motivation","text":"The goal of single-cell transcriptomics is to measure the transcriptional states of large numbers of cells simultaneously. The input to a scRNA-seq method is a collection of cells, possibly from intact tissue, or in dissociated form. Formally, the desired output is a transcripts x cells or genes x cells matrix that describes, for each cell, the abundance of its constituent transcripts or genes. More generally, single-cell genomics methods seek to measure not just transcriptional state, but other modalities in cells, e.g. protein abundances, epigenetic states, cellular morphology, etc. The ideal single-cell technology should thus: Be universal in terms of cell size, type and state. Perform in situ measurements. Have no minimum input requirements. Assay every cell, i.e. have a 100% capture rate . Detect every transcript in every cell, i.e. have 100% sensitivity . Identify individual transcripts by their full-length sequence . Assign transcripts correctly to cells, e.g. no doublets . Be compatible with additional multimodal measurements . Be cost effective per cell. Be easy to use . Be open source so that it is transparent, and results from it reproducible. There is no method satisfying all of these requirements, however progress has been rapid. The development of single-cell RNA-seq technologies and their adoption by biologists, has been remarkable. Svensson et al. 2019 describes a database of articles which present single-cell RNA-seq experiments, and the graph below, rendered from the current version of the database , makes clear the exponential growth in single-cell transcriptomics: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 #@title Growth of single-cell RNA-seq df = pd.read_csv('http://nxn.se/single-cell-studies/data.tsv', sep='\\t') # converts string to date format, can only be run once! df['Date'] = pd.to_datetime(df['Date'], format='%Y%m%d') # converts string of reported cells total to float, can only be run once! df['Reported cells total'] = df['Reported cells total'].str.replace(',', '').map(float) # plot number of studies over time fig, ax = plt.subplots(figsize=(12, 5)) papers = pd.read_csv('http://nxn.se/single-cell-studies/data.tsv', sep='\\t') papers['Datetime'] = pd.to_datetime(papers['Date'], format='%Y%m%d') papers = papers.sort_values(\"Date\") papers[\"count\"] = 1 x = papers.Datetime y = papers[\"count\"].groupby(papers.Datetime.dt.time).cumsum() ax.plot(x, y, color=\"k\") ax.set_xlabel(\"Date\") ax.set_ylabel(\"Cumulative number of studies\") plt.show() There are many different scRNA-seq technologies in use and under development, but broadly they fall into a few categories - well-based methods (e.g. Fluidigm SMARTer C1, Smart-seq2) - droplet-based methods (e.g. Drop-seq, InDrops, 10X Genomics Chromium) - spatial transcriptomics approaches (e.g. MERFISH, SEQFISH) At the time of initial writing of this document (2019), droplet-based approaches have become popular due to their relative low-cost, easy of use, and scalability. This is evident in a breakdown of articles by technology used: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 #@title Technologies used def tidy_split(df, column, sep='|', keep=False): indexes = list() new_values = list() df = df.dropna(subset=[column]) for i, presplit in enumerate(df[column].astype(str)): values = presplit.split(sep) if keep and len(values) > 1: indexes.append(i) new_values.append(presplit) for value in values: indexes.append(i) new_values.append(value) new_df = df.iloc[indexes, :].copy() new_df[column] = new_values return new_df ts = pd.Timestamp tdf = tidy_split(df, 'Technique', ' & ') t_dict = {k: k for k in tdf['Technique'].value_counts().head(5).index} tdf['Technique'] = tdf['Technique'].map(lambda s: t_dict.get(s, 'Other')) techs = list( tdf['Technique'] .value_counts() .sort_index() .index .difference(['Other']) ) techs.append('Other') tdf['Technique'] = ( pd.Categorical( tdf['Technique'], categories=techs, ordered=True ) ) def desaturate(color, prop): # Check inputs # if not 0 <= prop <= 1: # raise ValueError(\"prop must be between 0 and 1\") # Get rgb tuple rep rgb = mplcol.colorConverter.to_rgb(color) # Convert to hls h, l, s = colorsys.rgb_to_hls(*rgb) # Desaturate the saturation channel # l *= prop l = 0.8 # Convert back to rgb new_color = colorsys.hls_to_rgb(h, l, s) hex_color = '#{:02x}{:02x}{:02x}'.format(*map(lambda c: int(c * 255), new_color)) return hex_color # lighten matplotlib default colors clrs = list(map(lambda c: desaturate(c, 1.2), ['C0', 'C1', 'C2', 'C3', 'C4', 'black'])) #### Plot number of studies per month by technique per_month = ( tdf .groupby('Technique') .resample('1M', on='Date') .count()['DOI'] .reset_index() ) p.options.figure_size = (9, 2) fig = ( p.ggplot( p.aes(x='Date', y='DOI', fill='Technique'), data=per_month.query('Date > @ts(\"20130101T010101\")') ) + p.geom_bar(stat='identity', color='grey') + p.theme_minimal(base_family='DejaVu Sans') + p.scale_x_datetime( breaks=date_breaks('1 years'), labels=date_format('%Y') ) + p.labs(y='Number of studies') + p.scale_fill_manual(clrs) ) fig <ggplot: (-9223363288449985206)> We therefore restrict this exposition to droplet-based technologies.","title":"Motivation"},{"location":"tutorials/Introduction_single_cell_RNA_seq/#droplet-based-methods","text":"Droplet based single-cell RNA-seq methods were popularized by a pair of papers published concurrently in 2015: - Macosko et al., Highly parallel genome-wide expression profiling of individual cells using nanoliter droplets , 2015. DOI:10.1016/j.cell.2015.05.002 - describes Drop-seq. - Klein et al., Droplet barcoding for single-cell transcriptomics applied to embryonic stem cells , 2015. DOI:10.1016/j.cell.2015.04.044 - descibes inDrops. Both of the methods makes use of developments in microfluidics published in: - Song, Chen, Ismagilov, Reactions in droplets in microfluidic channels , 2006. DOI:10.1002/anie.200601554 - Guo, Rotem, Heyman and Weitz, Droplet microfluidics for high-throughput biological assays , 2012. DOI:10.1039/C2LC21147E","title":"Droplet-based methods"},{"location":"tutorials/Introduction_single_cell_RNA_seq/#overview","text":"An overview of how a droplet based scRNA-seq method works is illustrated in a figure from the Drop-seq Macosko et al. 2015 paper: A microfluidic device is used to generate an emulsion, which consists of aqueous droplets in oil. The droplets are used to encapsulate cells, beads and reagents. In other words, each droplet is a \"mini laboratory\" in which the RNA from a single-cell can be captured and prepared for identification. Thus, the consistuent parts are as follows: an emulsion (white circles containing beads and cells on the right hand-side of the figure). dissociated cells (depicted as odd-shaped colored objects in the figure). beads (flowing in from the left hand side of the figure).","title":"Overview"},{"location":"tutorials/Introduction_single_cell_RNA_seq/#emulsions","text":"The foundation of droplet based single-cell RNA-seq methods are mono-dispersed emulsions . Mono-dispersed refers to the requirements that droplets are of (near) uniform size. Mono-dispersed emulsions can be generated with a microfluidic device, as shown below. The droplets are being \"pinched off\" at the junction, and one can see a polystyrene bead being captured in one droplet, while others are empty. The movie is from the McCarolll Drop-seq tutorial courtesy of Patrick Stumpf, Matthew Rose-Zerilli, Rosanna Smith, Martin Fischlechner & Jonathan West at the Centre for Hybrid Biodevices & Cancer Sciences Unit at the University of Southampton.","title":"Emulsions"},{"location":"tutorials/Introduction_single_cell_RNA_seq/#beads","text":"The figure above, reproduce from Klein et al. 2015, shows the procedure used to make hydrogel beads for inDrops. Every bead contains the same barcode sequence, while the barcode sequences on two different beads are distinct. The barcode and UMI structure for a variety of technologies is viewable in a compilation by Xi Chen.","title":"Beads"},{"location":"tutorials/Introduction_single_cell_RNA_seq/#single-cell-suspensions","text":"In order to assay the transcriptomes of individual cells with droplet-based single-cell RNA-seq technologies, it is necessary to first dissociate tissue. Procedures for tissue dissociation are varied, and highly dependent on the organism, type of tissue, and many other factors. Protocols may be be enzymatic, but can also utilize mechanical dissociators. The talk below provides an introduction to tissue handling and dissociation. 1 2 3 #@title Tissue handling and dissociation from IPython.display import HTML HTML('<iframe width=\"882\" height=\"496\" src=\"https://www.youtube.com/embed/ARozvI4AbS8\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>')","title":"Single cell suspensions"},{"location":"tutorials/Introduction_single_cell_RNA_seq/#statistics-of-beads-cells-in-droplets","text":"","title":"Statistics of beads &amp; cells in droplets"},{"location":"tutorials/Introduction_single_cell_RNA_seq/#the-binomial-distribution","text":"An understanding of droplet-based single-cell RNA-seq requires consideration of the statistics describing the capture of cells and beads in droplets. Suppose that in an experiment multiple droplets have been formed, and focus on one of the droplets. Assume that the probability that any single one of $n$ cells were captured inside it is $p$. We can calculate the probability that $k$ cells have been captured in the droplet as follows: $$ \\mathbb{P}({\\mbox Droplet\\ contains\\ k\\ cells}) = \\binom{n}{k}p^k(1-p)^{n-k}.$$ The expected number of cells in the droplet is $$\\lambda := \\sum_{k=0}^n k \\binom{n}{k}p^k(1-p)^{n-k} = n \\cdot p.$$ We plot this distribution on number of cells in a droplet below. It is called the Binomial distribution and has two parameters: $n$ and $p$. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 #@title Binomial distribution { run: \"auto\" } n = 10#@param {type:\"integer\"} p = 0.02 #@param {type:\"slider\", min:0, max:1, step:0.01} fig, ax = plt.subplots(figsize=(7, 4)) s = 10 x = np.arange(s) y = binom.pmf(x,n,p) ax.bar(x, y, color=\"k\", label=\"Binomial n, p = ({}, {})\".format(n,p)) ax.set_xlabel(\"Number of Trials\") ax.set_ylabel(\"Probability\") ax.set_xticks(x) ax.legend() plt.show() With $n=10$ and $p=0.02$, it's quite probable that the droplet is empty, and while possible that it contains one cell, unlikely that it has 2 or more. This is a good regime for a single-cell experiment; we will see that it is problematic if two cells are captured in a single droplet. Empty droplets are not problematic in the sense that they will not lead to data, and can therefore be ignored.","title":"The binomial distribution"},{"location":"tutorials/Introduction_single_cell_RNA_seq/#the-poisson-distribution","text":"The Binomial distribution can be difficult to work with in practice. Suppose, for example, that $n=1000$ and $p=0.002$. Suppose that we are interested in the probability of seeing 431 cells in a droplet. This probability is given by $$\\binom{1000}{421}0.02^{421}(1-0.02)^{1000-431},$$ which is evidently a difficult number to calculate exactly. A practical alternative to the binmomial is the Poisson distribution. The Poisson distribution has one parameter, and its support is the non-negative integers. A random variable $X$ is Poisson distributed if $$\\mathbb{P}(X=k)\\quad = \\quad \\frac{e^{-\\lambda}\\lambda^k}{k!}.$$ The Poisson limit theorem states that if $p_n$ is a sequence of real numbers in $[0,1]$ with the sequence $np_n$ converging to to a finite limit $\\lambda$, then $${\\mbox lim}_{n \\rightarrow \\infty} \\binom{n}{k}p_n^{k}(1-p_n)^{n-k} = e^{-\\lambda}\\frac{\\lambda^k}{k!}.$$ Thus, the Poisson distribution serves as a useful, tractable distribution to work with in lieu of the Binomial distribution for large $n$ and small $p$. The histogram below can be used to explore the Poisson and its relationship to the binomial 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 #@title Binomial - Poisson comparison { run: \"auto\" } n = 10#@param {type:\"integer\"} p = 0.02 #@param {type:\"slider\", min:0, max:1, step:0.01} s = 10 lambda_param = n*p fig, ax = plt.subplots(figsize=(14, 4), ncols=2) x = np.arange(s) y = poisson.pmf(x, lambda_param) ax[0].bar(x, y, color=\"k\", label=\"Binomial n, p = ({}, {})\".format(n,p)) ax[0].set_xlabel(\"Number of Trials\") ax[0].set_ylabel(\"Probability\") ax[0].set_xticks(x) ax[0].legend() x = np.arange(s) y = binom.pmf(x,n,p) ax[1].bar(x, y, color=\"k\", label=\"Poisson $\\lambda$={}\".format(lambda_param)) ax[1].set_xlabel(\"Number of Trials\") ax[1].set_ylabel(\"Probability\") ax[1].set_xticks(x) ax[1].legend() plt.show() We therefore posit that $$ \\mathbb{P}({\\mbox Droplet\\ contains\\ k\\ cells}) = \\frac{e^{-\\lambda}\\lambda^k}{k!}$$ and $$ \\mathbb{P}({\\mbox Droplet\\ contains\\ j\\ beads}) = \\frac{e^{-\\mu}\\mu^j}{j!}.$$","title":"The Poisson distribution"},{"location":"tutorials/Introduction_single_cell_RNA_seq/#droplet-tuning","text":"","title":"Droplet tuning"},{"location":"tutorials/Introduction_single_cell_RNA_seq/#cell-capture-and-bead-overload","text":"The cell capture rate is the probability that a droplet has at least one bead, and is given by $1-e^{-\\mu}$. The bead overload rate is the rate at which captured single cells are associated with two or more different barcodes, which will happen when multiple beads are loaded into a droplet with one cell. The probability this happens is $$\\frac{1-e^{-\\mu}-\\mu e^{-\\mu}}{1-e^{-\\mu}}.$$ This leads to a tradeoff, as shown below. 1 2 3 4 5 6 7 8 9 10 11 12 13 #@title Tradeoff { run: \"auto\" } fig, ax = plt.subplots(figsize=(5,5)) mu = np.arange(0, 10, 0.1) x = 1 - np.exp(-mu) y = (1 - np.exp(-mu)-mu*np.exp(-mu))/(1-np.exp(-mu)) ax.plot(x, y, color='k') ax.set_xlabel(\"Cell capture rate\") ax.set_ylabel(\"Bead overload rate\") plt.show()","title":"Cell capture and bead overload"},{"location":"tutorials/Introduction_single_cell_RNA_seq/#sub-poisson-loading","text":"In order to circumvent the limit posed by a Poisson process for beads in droplets, the inDrops method uses tightly packed hydrogel beads that can be injected into droplets without loss. This approach, which leads to \" sub-Poisson loading \" is also used by 10X Genomics, and allows for increased capture rate. The difference is shown in two videos from the Abate lab linked to below. The first video, shows beads loaded being loaded in droplets with Poisson statistics: 1 2 #@title Poisson loading HTML('<iframe width=\"688\" height=\"387\" src=\"https://www.youtube.com/embed/usK71SG30t0?autoplay=1&loop=1&playlist=usK71SG30t0\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>') The next video shows sub-Poisson loading with hydrogel beads. In this case the flow rate has been set so that exactly two beads are situated in each droplet. 1 2 #@title Sub-Poisson loading { run: \"auto\" } HTML('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/2q1Lt9DWmRQ?autoplay=1&loop=1&playlist=2q1Lt9DWmRQ\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>') The following shows the types of beads used for different droplet-based scRNA-seq methods, and associated properties: Property Drop-seq inDrops 10x genomics Bead material Polystyrene Hydrogel Hydrogel Loading dynamics Poisson sub-Poisson sub-Poisson Dissolvable No No Yes Barcode release No UV release Chemical release Customizable Demonstrated Not shown Feasible Licensing Open source Open Source Proprietary Availability Beads are sold Commercial Commercial","title":"Sub-Poisson loading"},{"location":"tutorials/Introduction_single_cell_RNA_seq/#barcode-collisions","text":"Barcode collisions arise when two cells are separately encapsulated with beads that happen to contain identical barcodes. For $n$ assayed cells with $m$ barcodes, the barcode collision rate is the expected proportion of assayed cells that did not receive a unique barcode, i.e. $$1-\\frac{\\mathbb{E}[\\mbox{cells with a unique barcode}]}{\\mbox{number of cells}}$$ $$= 1-(1-\\frac{1}{m})^{n-1} \\approx 1-\\left(\\frac{1}{e}\\right)^\\frac{n}{m}.$$ Avoiding barcode collisions requires high barcode diversity, i.e. a small ratio of $\\frac{n}{m}$. 1 2 3 4 5 6 7 8 9 10 11 12 13 #@title Diversity and collisions { run: \"auto\" } fig, ax = plt.subplots(figsize=(5,5)) bc = np.arange(0, 1, 0.01) x = bc y = 1 - np.exp(-bc) ax.plot(x, y, color='k') ax.set_xlabel(\"n/m\") ax.set_ylabel(\"Barcode collision rate\") plt.show()","title":"Barcode collisions"},{"location":"tutorials/Introduction_single_cell_RNA_seq/#barcode-diversity-and-length","text":"A 1% barcode collision rate requires a barcode diversity of ~1%, i.e. the number of barcodes should be 100 times the number of cells. The number of barcodes from a sequence of length $L$ is $4^L$. Therefore, to assay $n$ cells, the barcode sequence must be of length at least $log_4n+3\\frac{1}{3}$. This is a minimum and does not account for the need to be robust to sequencing errors.","title":"Barcode diversity and length"},{"location":"tutorials/Introduction_single_cell_RNA_seq/#technical-doublets","text":"Technical doublets arise when two or more cells are captured in a droplet with a single bead. The technical doublet rate is therefore the probability of capturing two or more cells in a droplet given that at least one cell has been captured in a droplet: $\\frac{1-e^{-\\lambda}-\\lambda e^{-\\lambda}}{1-e^{-\\lambda}}$. Note that \"overloading\" a droplet-based single-cell experiment by loading more cells while keeping flow rates constant will increase the number of technical doublets due to an effective increase in $\\lambda$ and also the number of synthetic doublets due to an increase in barcode diversity.","title":"Technical doublets"},{"location":"tutorials/Introduction_single_cell_RNA_seq/#the-barnyard-plot","text":"Technical doublet rates can be measured by experiments in which a mixture of cells from two different species are assayed together. For example, if mouse and human cells are pooled prior to single-cell RNA-seq, the resultant reads ought to be assignable to either human or mouse. If a droplet contained a \"mixed\" doublet, i.e. two cells one of which is from human and the other from mouse, it will generate reads some of which can be aligned to mouse, and some to human. An example from a 10X Genomics dataset ( 5k 1:1 mixture of fresh frozen human (HEK293T) and mouse (NIH3T3) cells ) is shown in the plot below, which is called a Barnyard plot in Macosko et al. 2015 . 1 2 3 4 %%capture # Download a matrix of human and mouse !wget http://cf.10xgenomics.com/samples/cell-exp/3.0.0/hgmm_1k_v2/hgmm_1k_v2_filtered_feature_bc_matrix.tar.gz !tar -xvf hgmm_1k_v2_filtered_feature_bc_matrix.tar.gz 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 #@title Human & mouse PBMCs mtx = csr_matrix(mmread(\"/content/filtered_feature_bc_matrix/matrix.mtx.gz\").T) genes = pd.read_csv(\"/content/filtered_feature_bc_matrix/features.tsv.gz\", header=None, names=[\"gene_id\", \"gene_name\", \"extra\"], sep=\"\\t\") cells = pd.read_csv(\"/content/filtered_feature_bc_matrix/barcodes.tsv.gz\", header=None, names=[\"cell_barcode\"], sep=\"\\t\") adata = anndata.AnnData(X=mtx, var=genes, obs=cells) adata.var[\"human\"] = adata.var[\"gene_id\"].str.contains(\"hg19\").values x = (mtx[:,adata.var[\"human\"].values]).sum(axis=1) y = (mtx[:,~adata.var[\"human\"].values]).sum(axis=1) fig, ax = plt.subplots(figsize=(5,5)) x = np.asarray(x).reshape(-1) y = np.asarray(y).reshape(-1) ax.scatter(x, y, color='k') ax.set_xlabel(\"Human UMI counts per cell\") ax.set_ylabel(\"Mouse UMI counts per cell\") ax.xaxis.set_major_formatter(mpl.ticker.StrMethodFormatter('{x:,.0f}')) ax.yaxis.set_major_formatter(mpl.ticker.StrMethodFormatter('{x:,.0f}')) plt.show() THe plot shows that there are only 7 doublets out of 5,000 cells in this experiment. This is an unusually small number and atypical of most experiments, where doublet rates are between 5%--15% (see DePasquale et al. 2018 ); perhaps the 5k human mouse PBMC dataset data is articularly \"clean\" as it is an advertisement distributed by 10X Genomics.","title":"The barnyard plot"},{"location":"tutorials/Introduction_single_cell_RNA_seq/#blooms-correction","text":"The 7 doublets identifiable by eye in the plot above are all mixed doublets , i.e. they contain one human and one mouse cell. However doublets may consist of two mouse cells, or two human cells. If the number of droplets containing at least one human cells is $n_1$, the number containing at least one mouse cell is $n_2$, and the number of mixed doublets is $n_{1,2}$, then an estimate for the actual doublet rate can be obtained from the calculation below ( Bloom 2018 ): Given $n_1, n_2$ and $n_{1,2}$ as described above (note that $n_1$ is the number of cells on the x axis + the number of mixed doublets and $n_2$ is the number of cells on the y axis + the number of mixed doublets), then in expectation $$\\frac{n_1}{N} \\cdot \\frac{n_2}{N} = \\frac{n_{1,2}}{N}, $$ where $N$ is the total number of droplets. From this we see that $$ \\hat{N} = \\frac{n_1 \\cdot n_2}{n_{1,2}}.$$ This is the maximum likelihood Lincoln-Petersen estimator for population size from mark and recapture. Let $\\mu_1$ nad $\\mu_2$ be the Poisson rates for the respective types of cells, i.e. the average number of cells of each type per droplet. Then $$ \\hat{\\mu}_1 = -\\mbox{ln } \\left( \\frac{N-n_1}{N} \\right)$$ and $$ \\hat{\\mu}_2 = -\\mbox{ln } \\left( \\frac{N-n_2}{N} \\right).$$ From this the doublet rate $D$ can be estimated as $$\\hat{D} = 1 - \\frac{(\\mu_1+\\mu_2)e^{-\\mu_1+\\mu_2}}{1-e^{-\\mu_1-\\mu_2}}.$$","title":"Bloom's correction"},{"location":"tutorials/Introduction_single_cell_RNA_seq/#biological-doublets","text":"Biological doublets arise when two cells form a discrete unit that does not break apart during disruption to form a single-cell suspension. Note that biological doublets cannot be detected in barnyard plots. One approach to avoiding biological doublets is to perform single-nuclei RNA-seq. See, e.g. Habib et al., 2017 . However, biological doublets are not necessarily just a technical artifact to be avoided. Halpern et al., 2018 utilizes biological doublets of hepatocytes and liver endothelial cells to assign tissue coordinates to liver endothelial cells via imputation from their hepatocyte partners.","title":"Biological doublets"},{"location":"tutorials/Introduction_single_cell_RNA_seq/#unique-molecular-identifiers","text":"The number of distinct UMIs on a bead in a droplet is at most $4^L$ where $L$ is the number of UMI bases. For example, for 10X Genomics v2 technology $L=10$ and for 10X Genomics v3 technology $L=12$. Melsted, Booeshaghi et al. 2019 show how to estimate the number of the actual distinct UMIs on each bead for which data is obtained in a scRNA-seq experiment.","title":"Unique Molecular Identifiers"},{"location":"tutorials/Introduction_single_cell_RNA_seq/#summary","text":"Selection of a single-cell RNA-seq method requires choosing among many tradeoffs that reflect the underlying technologies. The table below, from From Zhang et al. 2019. DOI:10.1016/j.molcel.2018.10.020 , summarizes the three most popular droplet-based single-cell RNA-seq assays: The generation of single-cell RNA-seq data is just the first step in understanding the transcriptomes cells. To interpret the data reads must be aligned or pseudoaligned, UMIs counted, and large cell x gene matrices examined. The growth in single-cell RNA-seq analysis tools for these tasks has been breathtaking. The graph below, plotted from real-time data downloaded from the scRNA-seq tools database , shows the number of tools published since 2016. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 #@title Growth of single-cell tools { run: \"auto\" } tools = pd.read_csv('https://raw.githubusercontent.com/Oshlack/scRNA-tools/master/database/tools.tsv', sep='\\t') tools[\"Datetime\"] = pd.to_datetime(tools[\"Added\"]) tools = tools.sort_values(\"Added\") tools[\"count\"] = 1 fig, ax = plt.subplots(figsize=(12, 5)) x = tools.Datetime y = tools[\"count\"].groupby(tools.Datetime.dt.time).cumsum() ax.plot(x, y, color=\"k\") ax.set_xlabel(\"Date\") ax.set_ylabel(\"Number of tools\") ax.tick_params(axis='x', rotation=45) plt.show() In fact, the rate of growth of single-cell RNA-seq tools is similar to that of single-cell RNA-seq studies : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 #@title scRNA-seq tools vs. studies linear regression date_papers = papers.groupby(\"Datetime\")[\"count\"].sum() date_tools = tools.groupby(\"Datetime\")[\"count\"].sum() dates = pd.date_range(start='7/26/2002', end='01/01/2025') combined = pd.DataFrame(index=dates) combined[\"tool_counts\"] = combined.index.map(date_tools) combined[\"paper_counts\"] = combined.index.map(date_papers) combined = combined.fillna(0) combined[\"Datetime\"] = combined.index.values fig, ax = plt.subplots(figsize=(5,5)) x = combined[\"paper_counts\"].groupby(combined.Datetime.dt.time).cumsum() y = combined[\"tool_counts\"].groupby(combined.Datetime.dt.time).cumsum() ax.scatter(x, y, color=\"k\") regr = linear_model.LinearRegression() x = x.values[:, np.newaxis] regr.fit(x, y.values) xx = np.linspace(0, max(x), 200) yy = regr.intercept_ + regr.coef_*xx ax.plot(xx, yy, color=\"r\", label=f\"{regr.intercept_:,.2f} + {regr.coef_[0]:,.2f}*x\") lims = [np.min([ax.get_xlim(), ax.get_ylim()]), # min of both axes np.max([ax.get_xlim(), ax.get_ylim()])] # max of both axes ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0) ax.set_aspect('equal') ax.set_xlim(lims) ax.set_ylim(lims) ax.set_xlabel(\"Cumulative Papers\") ax.set_ylabel(\"Cumulative Tools\") ax.legend() plt.show() Next step: to learn how to analyze single-cell RNA-seq data, visit the kallistobus.tools site tutorials site and explore the \"Introduction 1: pre-processing and quality control\" notebook in Python or R . Feedback : please report any issues, or submit pull requests for improvements, in the Github repository where this notebook is located .","title":"Summary"},{"location":"tutorials/diagnostic/","text":"1 Diagnostic results \u00b6 1 ! git clone https : // github . com / pachterlab / BLCSBGLKP_2020 . git Cloning into ' BLCSBGLKP_2020 ' ... remote : Enumerating objects : 186 , done . \u001b [ K remote : Counting objects : 100 % ( 186 / 186 ), done . \u001b [ K remote : Compressing objects : 100 % ( 171 / 171 ), done . \u001b [ K remote : Total 186 ( delta 57 ), reused 75 ( delta 10 ), pack - reused 0 \u001b [ K Receiving objects : 100 % ( 186 / 186 ), 34.16 MiB | 25.95 MiB / s , done . Resolving deltas : 100 % ( 57 / 57 ), done . 1 ! pip install anndata Collecting anndata \u001b [ ? 25 l Downloading https : // files . pythonhosted . org / packages / 5 b / c8 / 5 c594a95ba293433dfe1cf188075ccbabe495bf2d291be744974aca85ffc / anndata - 0.7 . 1 - py3 - none - any . whl ( 97 kB ) \u001b [ K | \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 102 kB 3.7 MB / s \u001b [ ? 25 hRequirement already satisfied : importlib - metadata >= 0.7 ; python_version < \"3.8\" in / usr / local / lib / python3 . 6 / dist - packages ( from anndata ) ( 1.6 . 0 ) Requirement already satisfied : pandas >= 0.23 . 0 in / usr / local / lib / python3 . 6 / dist - packages ( from anndata ) ( 1.0 . 3 ) Requirement already satisfied : natsort in / usr / local / lib / python3 . 6 / dist - packages ( from anndata ) ( 5.5 . 0 ) Requirement already satisfied : packaging in / usr / local / lib / python3 . 6 / dist - packages ( from anndata ) ( 20.3 ) Requirement already satisfied : scipy ~= 1.0 in / usr / local / lib / python3 . 6 / dist - packages ( from anndata ) ( 1.4 . 1 ) Requirement already satisfied : numpy ~= 1.14 in / usr / local / lib / python3 . 6 / dist - packages ( from anndata ) ( 1.18 . 4 ) Requirement already satisfied : h5py in / usr / local / lib / python3 . 6 / dist - packages ( from anndata ) ( 2.10 . 0 ) Requirement already satisfied : zipp >= 0.5 in / usr / local / lib / python3 . 6 / dist - packages ( from importlib - metadata >= 0.7 ; python_version < \"3.8\" -> anndata ) ( 3.1 . 0 ) Requirement already satisfied : python - dateutil >= 2.6 . 1 in / usr / local / lib / python3 . 6 / dist - packages ( from pandas >= 0.23 . 0 -> anndata ) ( 2.8 . 1 ) Requirement already satisfied : pytz >= 2017.2 in / usr / local / lib / python3 . 6 / dist - packages ( from pandas >= 0.23 . 0 -> anndata ) ( 2018.9 ) Requirement already satisfied : six in / usr / local / lib / python3 . 6 / dist - packages ( from packaging -> anndata ) ( 1.12 . 0 ) Requirement already satisfied : pyparsing >= 2.0 . 2 in / usr / local / lib / python3 . 6 / dist - packages ( from packaging -> anndata ) ( 2.4 . 7 ) Installing collected packages : anndata Successfully installed anndata - 0.7 . 1 Obtain diagnostic results from the adata \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 import pandas as pd import numpy as np import matplotlib.pyplot as plt import string import anndata from collections import defaultdict from collections import OrderedDict from mpl_toolkits.axes_grid1 import make_axes_locatable import matplotlib as mpl import matplotlib.patches as mpatches from sklearn.manifold import TSNE from sklearn.cluster import KMeans from sklearn.preprocessing import scale from sklearn.preprocessing import normalize from sklearn.decomposition import TruncatedSVD from sklearn.linear_model import LogisticRegression from sklearn.model_selection import train_test_split from sklearn import metrics from scipy.special import expit as sigmoid def nd ( arr ): return np . asarray ( arr ) . reshape ( - 1 ) def yex ( ax ): lims = [ np . min ([ ax . get_xlim (), ax . get_ylim ()]), # min of both axes np . max ([ ax . get_xlim (), ax . get_ylim ()]), # max of both axes ] # now plot both limits against eachother ax . plot ( lims , lims , 'k-' , alpha = 0.75 , zorder = 0 ) ax . set_aspect ( 'equal' ) ax . set_xlim ( lims ) ax . set_ylim ( lims ) return ax def main ( X , y1 , y2 ): y = np . asarray ([ y1 , y2 ]) . T X_train , X_test , y_train , y_test = train_test_split ( X , y , test_size = 0.5 , random_state = 43 ) clf = LogisticRegression ( random_state = 43 , dual = False , max_iter = 1000 , tol = 1e-6 ) clf . fit ( X_train , y_train [:, 0 ]) y_pred = clf . predict ( X_test ) # T = True, F = False, P = Positive, N = Negative # Model Precision: TP/(TP+FP) # Model Recall: TP/(TP+FN) print ( \"Score: {:,.4f} \" . format ( clf . score ( X_test , y_test [:, 0 ] . astype ( int )))) print ( \"Precision: {:,.4f} \" . format ( metrics . precision_score ( y_test [:, 0 ] . astype ( int ), y_pred . astype ( int )))) print ( \"Recall: {:,.4f} \" . format ( metrics . recall_score ( y_test [:, 0 ] . astype ( int ), y_pred . astype ( int )))) w = clf . coef_ [ 0 ] b = clf . intercept_ [ 0 ] return ( X_train , X_test , y_train , y_test , y_pred , w , b , clf ) def plot ( X , y , xidx , yidx , xlabel , ylabel , w , b , y_pred ): N = 1000 r = 0.2 # Get the test data c = nd ( np . log1p ( y [:, 1 ])) x = nd ( X [:, xidx ]) y = nd ( X [:, yidx ]) # Find the limits xlims = ( np . min ( x ) * ( 1 - r ), np . max ( x ) * ( 1 + r )) ylims = ( np . min ( y ) * ( 1 - r ), np . max ( y ) * ( 1 + r )) # compute boundary line xx = np . linspace ( * xlims , len ( x )) yy = ( - xx * w [ xidx ] - b ) / w [ yidx ] X , Y = np . meshgrid ( np . linspace ( * xlims , N ), np . linspace ( * ylims , N )) YY = ( - X * w [ xidx ] - b ) / w [ yidx ] ############################################################### ax . set_xlim ( * xlims ) ax . set_ylim ( * ylims ) circle_m = y_pred == 1 square_m = y_pred == 0 circle_color = c [ circle_m ] square_color = c [ square_m ] ### Scatter plot of points circles = ax . scatter ( x [ circle_m ], y [ circle_m ], c = circle_color , s = 100 , marker = \"o\" , edgecolors = \"black\" , cmap = \"plasma\" , label = \"$+$ Viral RNA\" ) squares = ax . scatter ( x [ square_m ], y [ square_m ], c = square_color , s = 100 , marker = \"s\" , edgecolors = \"black\" , cmap = \"plasma\" , label = \"$-$ Viral RNA\" ) sc = ax . scatter ( x , y , c = c , s = 0 , edgecolors = \"black\" , cmap = \"plasma\" ) ### Plot boundary line # note that here we solve the above equation for y using the # coefficients and the intercept thresh = ax . plot ( xx , yy , linestyle = \"--\" , color = \"black\" , linewidth = 2 , label = \"Theshold\" ) ### Plot logistic function # Perpendicular from the line is the probability that a sample # has viral RNA. This function is the logistic function and has # the form f(x) = 1/(1+exp(-(x-x0))) but we only care about variation # perpendicular to the line so we use Y and YY Z = sigmoid ( Y - YY ) # Since we want probability of 1 to be above the line, we do 1-Z cs = ax . imshow ( Z , vmin = 0. , vmax = 1. , cmap = plt . cm . coolwarm , origin = 'lower' , extent = [ * xlims , * ylims ]) #### Colorbar for RNA amount plt . colorbar ( sc , label = \"log(Viral RNA molecules + 1)\" ) # Colorbar for Probability plt . colorbar ( cs , label = \"Probability of + Virus\" ) ############################################################### ## Prettying up the plot, adding pos = mpatches . Patch ( color = \"#D43F3A\" , label = 'Virus detected' ) neg = mpatches . Patch ( color = \"#3182bd\" , label = 'Virus not detected' ) handles , labels = ax . get_legend_handles_labels () order = [ 0 , 2 , 1 ] handles = [ handles [ idx ] for idx in order ]; handles . append ( neg ); handles . append ( pos ) ax . legend ( handles = handles [:: - 1 ], fontsize = fsize - 5 ) ax . set_xlabel ( \"log( {} +1) amplicon counts\" . format ( xlabel )) ax . set_ylabel ( \"log( {} +1) amplicon counts\" . format ( ylabel )) ax . set_xlabel ( \"log( {} +1) amplicon counts\" . format ( \"Spikein\" )) ax . set_ylabel ( \"log( {} +1) amplicon counts\" . format ( \"Viral\" )) ax . xaxis . set_major_formatter ( mpl . ticker . StrMethodFormatter ( ' {x:,.0f} ' )) ax . yaxis . set_major_formatter ( mpl . ticker . StrMethodFormatter ( ' {x:,.0f} ' )) plt . tight_layout ( h_pad = 1 ) ax . set_title ( \"Logistic regression classifier on test data\" ) return ax def plot_LOD_adjusted ( X_test , y_test , xlabel , ylabel , xidx , yidx , w , b , y_pred ): x = np . exp ( X_test [:, xidx ]) y = np . exp ( X_test [:, yidx ]) c = pd . Series ( y_pred ) . map ( cm ) xx = y_test [:, 1 ] # xx[xx==0] = 0.1 # yy = y*w[yidx] + x*(w[xidx]) yy = ( y ** w [ yidx ]) / ( x ** ( - w [ xidx ])) ax . scatter ( xx , yy , c = c ) ### Make the plot pretty ax . set_xscale ( \"symlog\" ) ax . set_yscale ( \"symlog\" ) # bc = ax.axhline(y=np.exp(-b), linestyle=\"--\", label=\"Log. reg. boundary\", color=\"k\") ax . set_xlabel ( r \"Viral RNA molecules\" ) ax . set_ylabel ( r \"( {} +1)^( {:,.2f} ) / ( {} +1)^( {:,.2f} )\" . format ( ylabel , w [ yidx ], xlabel , w [ xidx ])) ax . set_ylabel ( r \"( {} +1)^( {:,.2f} ) / ( {} +1)^( {:,.2f} )\" . format ( \"Viral\" , w [ yidx ], \"Spikein\" , w [ xidx ])) # legend pos = mpatches . Patch ( color = \"#D43F3A\" , label = 'Virus detected' ) neg = mpatches . Patch ( color = \"#3182bd\" , label = 'Virus not detected' ) ax . legend ( handles = [ pos , neg ]) ax . set_title ( \"Adjusted normalization based on logistic regression\" ) return ax def plot_LOD_normal ( X_test , y_test , xlabel , ylabel , xidx , yidx , w , b , y_pred ): x = np . exp ( X_test [:, xidx ]) y = np . exp ( X_test [:, yidx ]) c = pd . Series ( y_pred ) . map ( cm ) xx = y_test [:, 1 ] # xx[xx==0] = 0.1 yy = y / x ax . scatter ( xx , yy , c = c ) ### Make the plot pretty ax . set_xscale ( \"symlog\" ) ax . set_yscale ( \"symlog\" ) ax . set_xlabel ( r \"Viral RNA molecules\" ) ax . set_ylabel ( r \"( {} +1) / ( {} +1))\" . format ( ylabel , xlabel )) ax . set_ylabel ( r \"( {} +1) / ( {} +1))\" . format ( \"Viral\" , \"Spikein\" )) # legend pos = mpatches . Patch ( color = \"#D43F3A\" , label = 'Virus detected' ) neg = mpatches . Patch ( color = \"#3182bd\" , label = 'Virus not detected' ) ax . legend ( handles = [ pos , neg ]) ax . set_title ( \"Standard normalization\" ) return ax cm = { 1 : \"#D43F3A\" , 0 : \"#3182bd\" } fsize = 20 plt . rcParams . update ({ 'font.size' : fsize }) % config InlineBackend . figure_format = 'retina' Load results \u00b6 1 adata = anndata . read_h5ad ( \"BLCSBGLKP_2020/data/kb/adata.h5ad\" ) Diagnostic testing \u00b6 We restrict our analysis to Plate1 HEK293 N ATCC_RNA We also drop the S genes since they were used in plate 2 only. We restrict our diagnostic analysis to Plate1 HEK293 N ATCC_RNA \u00b6 Other examples are shown after. 1 # Plate1 HEK293 N ATCC_RNA 1 2 3 4 5 6 7 8 9 10 11 12 13 a = np . logical_and (( adata . obs . plate == \"Plate1\" ) . values , ( adata . obs . lysate == \"HEK293\" ) . values ) b = np . logical_and ( a , adata . obs . Twist . values == 0 ) c = np . logical_and ( b , adata . obs . ATCC_viral . values == 0 ) data = adata [ b ] data . obs [ \"sick\" ] = ( data . obs . ATCC_RNA > 0 ) . astype ( int ) data = data [:, np . logical_or ( ~ data . var . gene . str . contains ( \"_S\" ), data . var . gene . str . contains ( \"RPP30\" ))] #data = data[:,data.var.sort_values(\"gene\").index] X = np . log1p ( data . layers [ \"raw\" ]) y1 = nd ( data . obs . sick . values . astype ( int )) y2 = nd ( data . obs . ATCC_RNA . values ) Trying to set attribute `.obs` of view, copying. We split our data in half. We train a logistic regression model on the training half, and test out our model on the testing half. For the sake of downstream plotting, we append the Twist RNA values to the real classificaation for each sample to make a sample x 2 matrix. This results in y_test having two columns. When splitting the data into training and testing the Twist RNA values associated with the split samples are retained. Since n_samples > n_genes we set dual=False in the logistic regresion classification since we are not interested in solving using the dual formulation of the regularization. The equation of the line is $w_1 x + w_2 y = b$. 1 data View of AnnData object with n_obs \u00d7 n_vars = 140 \u00d7 5 obs : 'bcs' , 'ecs' , 'cnt' , 'plate' , 'well' , 'lysate' , 'Twist' , 'ATCC_RNA' , 'ATCC_viral' , 'Twist_bool' , 'ATCC_viral_bool' , 'ATCC_RNA_bool' , 'sick' var : 'gene' obsm : 'X_pca' layers : 'log1p' , 'norm' , 'raw' , 'scale' 1 data . var .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } gene 0 N1 1 N1_spikein 2 RPP30 3 S2 4 S2_spikein 1 ( X_train , X_test , y_train , y_test , y_pred , w , b , clf ) = main ( X , y1 , y2 ) Score : 0.9571 Precision : 1.0000 Recall : 0.9388 1 2 3 4 5 6 7 8 fig , ax = plt . subplots ( figsize = ( 15 , 10 )) xlabel , ylabel = ( \"N1_spikein\" , \"N1\" ) xidx , yidx = ( np . where ( data . var . gene . values == xlabel )[ 0 ][ 0 ], np . where ( data . var . gene . values == ylabel )[ 0 ][ 0 ]) plot ( X_test , y_test , xidx , yidx , xlabel , ylabel , w , b , y_pred ) plt . show () Examine relative counts \u00b6 1 2 3 4 5 6 7 8 fig , ax = plt . subplots ( figsize = ( 10 , 10 )) xlabel , ylabel = ( \"N1_spikein\" , \"N1\" ) xidx , yidx = ( np . where ( data . var . gene . values == xlabel )[ 0 ][ 0 ], np . where ( data . var . gene . values == ylabel )[ 0 ][ 0 ]) plot_LOD_normal ( X_test , y_test , xlabel , ylabel , xidx , yidx , w , b , y_pred ) plt . show () Adjusted relative abundances \u00b6 The logistic regression was performed on the log(X+1) counts and the train/test/split gives back matrices that are log(X+1). In order to make plotting nicer (ie loglog scale axis), we exponentiate the matrices. Given $X_l = \\log(X+1)$ we wish to plot $\\frac{(Y+1)^{w_2}}{(X+1)^{w_1}}$ vs the amount of Twist RNA. We can plot $\\frac{(Y+1)^{w_2}}{(X+1)^{w_1}} = \\frac{exp(Y_l)^{w_2}}{exp(X_l)^{w_1}}$ vs the amount of Twist RNA. 1 2 3 4 5 6 7 8 fig , ax = plt . subplots ( figsize = ( 10 , 10 )) xlabel , ylabel = ( \"N1_spikein\" , \"N1\" ) xidx , yidx = ( np . where ( data . var . gene . values == xlabel )[ 0 ][ 0 ], np . where ( data . var . gene . values == ylabel )[ 0 ][ 0 ]) plot_LOD_adjusted ( X_test , y_test , xlabel , ylabel , xidx , yidx , w , b , y_pred ) plt . show () 1 2 print ( \"Precision: {:,.4f} \" . format ( metrics . precision_score ( y_test [:, 0 ], y_pred ))) print ( \"Recall: {:,.4f} \" . format ( metrics . recall_score ( y_test [:, 0 ], y_pred ))) Precision : 1.0000 Recall : 0.9388 Make these plots for all HEK experiments \u00b6 1 2 3 4 5 6 exp = [ ( \"Plate1\" , \"HEK293\" , \"N1\" , \"Twist\" ), ( \"Plate1\" , \"HEK293\" , \"N1\" , \"ATCC_RNA\" ), ( \"Plate2\" , \"HEK293\" , \"S2\" , \"Twist\" ), ( \"Plate2\" , \"HEK293\" , \"S2\" , \"ATCC_RNA\" ), ] 1 adata . var .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } gene 0 N1 1 N1_spikein 2 RPP30 3 S2 4 S2_spikein 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 adata = adata [:, adata . var . sort_values ( \"gene\" ) . index ] XXX = np . asarray ( adata . layers [ \"raw\" ]) plot_values = [] for ( p , l , g , c ) in exp : pmask = adata . obs . plate . values == p cmask = adata . obs [ c + \"_bool\" ] . values lmask = adata . obs . lysate . values == l m = np . logical_and ( np . logical_and ( pmask , cmask ), lmask ) vm = np . logical_or ( adata . var . gene . str . contains ( g ), adata . var . gene . str . contains ( \"RPP30\" )) . values gene_labels = adata . var . gene . values XX = XXX [ m ][:, vm ] X = np . log1p ( XX ) y1 = nd (( adata . obs [ m ][ c ] > 0 ) . astype ( int )) y2 = nd ( adata . obs [ m ][ c ] . values ) print ( \" {} \\t {} \\t {} \\t {} \" . format ( p , l , g [ 0 ], c )) ( X_train , X_test , y_train , y_test , y_pred , w , b , clf ) = main ( X , y1 , y2 ) ########################################################## fig , ax = plt . subplots ( figsize = ( 15 , 10 )) xlabel , ylabel = ( g + \"_spikein\" , g ) xidx , yidx = ( np . where ( gene_labels [ vm ] == xlabel )[ 0 ][ 0 ], np . where ( gene_labels [ vm ] == ylabel )[ 0 ][ 0 ]) plot ( X_test , y_test , xidx , yidx , xlabel , ylabel , w , b , y_pred ) ax . set_title ( \"Classifier: {} {} {} \" . format ( p , g [ 0 ], c )) plt . savefig ( \"./log_reg_ {} _ {} _ {} .png\" . format ( p , g , c ), bbox_inches = 'tight' , dpi = 300 ) plt . show () ########################################################## fig , ax = plt . subplots ( figsize = ( 10 , 10 )) plot_LOD_normal ( X_test , y_test , xlabel , ylabel , xidx , yidx , w , b , y_pred ) ax . set_title ( \"Standard curve: {} {} {} \" . format ( p , g [ 0 ], c )) #plt.savefig(\"./figs/lod_norm_{}_{}_{}.png\".format(p, g, c),bbox_inches='tight', dpi=300) plt . show () ########################################################## fig , ax = plt . subplots ( figsize = ( 10 , 10 )) plot_LOD_adjusted ( X_test , y_test , xlabel , ylabel , xidx , yidx , w , b , y_pred ) ax . set_title ( \"Adjusted standard curve: {} {} {} \" . format ( p , g [ 0 ], c )) #plt.savefig(\"./figs/lod_adj_{}_{}_{}.png\".format(p, g, c),bbox_inches='tight', dpi=300) plt . show () Plate1 HEK293 N Twist Score: 0.8333 Precision: 0.7391 Recall: 0.8947 Plate1 HEK293 N ATCC_RNA Score: 0.9571 Precision: 1.0000 Recall: 0.9388 Plate2 HEK293 S Twist Score: 0.9375 Precision: 0.9000 Recall: 0.9474 Plate2 HEK293 S ATCC_RNA Score: 0.8857 Precision: 0.9767 Recall: 0.8571 Diagnostic results are reported as probabilities \u00b6 1 pd . DataFrame ( clf . predict_proba ( X_test ), columns = [ \"- virus\" , \"+ virus\" ]) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } - virus + virus 0 0.988534 0.011466 1 0.005457 0.994543 2 0.975508 0.024492 3 0.005474 0.994526 4 0.057123 0.942877 ... ... ... 65 0.003317 0.996683 66 0.053892 0.946108 67 0.119947 0.880053 68 0.305283 0.694717 69 0.020065 0.979935 70 rows \u00d7 2 columns 1","title":"Diagnostic"},{"location":"tutorials/diagnostic/#diagnostic-results","text":"1 ! git clone https : // github . com / pachterlab / BLCSBGLKP_2020 . git Cloning into ' BLCSBGLKP_2020 ' ... remote : Enumerating objects : 186 , done . \u001b [ K remote : Counting objects : 100 % ( 186 / 186 ), done . \u001b [ K remote : Compressing objects : 100 % ( 171 / 171 ), done . \u001b [ K remote : Total 186 ( delta 57 ), reused 75 ( delta 10 ), pack - reused 0 \u001b [ K Receiving objects : 100 % ( 186 / 186 ), 34.16 MiB | 25.95 MiB / s , done . Resolving deltas : 100 % ( 57 / 57 ), done . 1 ! pip install anndata Collecting anndata \u001b [ ? 25 l Downloading https : // files . pythonhosted . org / packages / 5 b / c8 / 5 c594a95ba293433dfe1cf188075ccbabe495bf2d291be744974aca85ffc / anndata - 0.7 . 1 - py3 - none - any . whl ( 97 kB ) \u001b [ K | \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 102 kB 3.7 MB / s \u001b [ ? 25 hRequirement already satisfied : importlib - metadata >= 0.7 ; python_version < \"3.8\" in / usr / local / lib / python3 . 6 / dist - packages ( from anndata ) ( 1.6 . 0 ) Requirement already satisfied : pandas >= 0.23 . 0 in / usr / local / lib / python3 . 6 / dist - packages ( from anndata ) ( 1.0 . 3 ) Requirement already satisfied : natsort in / usr / local / lib / python3 . 6 / dist - packages ( from anndata ) ( 5.5 . 0 ) Requirement already satisfied : packaging in / usr / local / lib / python3 . 6 / dist - packages ( from anndata ) ( 20.3 ) Requirement already satisfied : scipy ~= 1.0 in / usr / local / lib / python3 . 6 / dist - packages ( from anndata ) ( 1.4 . 1 ) Requirement already satisfied : numpy ~= 1.14 in / usr / local / lib / python3 . 6 / dist - packages ( from anndata ) ( 1.18 . 4 ) Requirement already satisfied : h5py in / usr / local / lib / python3 . 6 / dist - packages ( from anndata ) ( 2.10 . 0 ) Requirement already satisfied : zipp >= 0.5 in / usr / local / lib / python3 . 6 / dist - packages ( from importlib - metadata >= 0.7 ; python_version < \"3.8\" -> anndata ) ( 3.1 . 0 ) Requirement already satisfied : python - dateutil >= 2.6 . 1 in / usr / local / lib / python3 . 6 / dist - packages ( from pandas >= 0.23 . 0 -> anndata ) ( 2.8 . 1 ) Requirement already satisfied : pytz >= 2017.2 in / usr / local / lib / python3 . 6 / dist - packages ( from pandas >= 0.23 . 0 -> anndata ) ( 2018.9 ) Requirement already satisfied : six in / usr / local / lib / python3 . 6 / dist - packages ( from packaging -> anndata ) ( 1.12 . 0 ) Requirement already satisfied : pyparsing >= 2.0 . 2 in / usr / local / lib / python3 . 6 / dist - packages ( from packaging -> anndata ) ( 2.4 . 7 ) Installing collected packages : anndata Successfully installed anndata - 0.7 . 1","title":"Diagnostic results"},{"location":"tutorials/diagnostic/#obtain-diagnostic-results-from-the-adata","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 import pandas as pd import numpy as np import matplotlib.pyplot as plt import string import anndata from collections import defaultdict from collections import OrderedDict from mpl_toolkits.axes_grid1 import make_axes_locatable import matplotlib as mpl import matplotlib.patches as mpatches from sklearn.manifold import TSNE from sklearn.cluster import KMeans from sklearn.preprocessing import scale from sklearn.preprocessing import normalize from sklearn.decomposition import TruncatedSVD from sklearn.linear_model import LogisticRegression from sklearn.model_selection import train_test_split from sklearn import metrics from scipy.special import expit as sigmoid def nd ( arr ): return np . asarray ( arr ) . reshape ( - 1 ) def yex ( ax ): lims = [ np . min ([ ax . get_xlim (), ax . get_ylim ()]), # min of both axes np . max ([ ax . get_xlim (), ax . get_ylim ()]), # max of both axes ] # now plot both limits against eachother ax . plot ( lims , lims , 'k-' , alpha = 0.75 , zorder = 0 ) ax . set_aspect ( 'equal' ) ax . set_xlim ( lims ) ax . set_ylim ( lims ) return ax def main ( X , y1 , y2 ): y = np . asarray ([ y1 , y2 ]) . T X_train , X_test , y_train , y_test = train_test_split ( X , y , test_size = 0.5 , random_state = 43 ) clf = LogisticRegression ( random_state = 43 , dual = False , max_iter = 1000 , tol = 1e-6 ) clf . fit ( X_train , y_train [:, 0 ]) y_pred = clf . predict ( X_test ) # T = True, F = False, P = Positive, N = Negative # Model Precision: TP/(TP+FP) # Model Recall: TP/(TP+FN) print ( \"Score: {:,.4f} \" . format ( clf . score ( X_test , y_test [:, 0 ] . astype ( int )))) print ( \"Precision: {:,.4f} \" . format ( metrics . precision_score ( y_test [:, 0 ] . astype ( int ), y_pred . astype ( int )))) print ( \"Recall: {:,.4f} \" . format ( metrics . recall_score ( y_test [:, 0 ] . astype ( int ), y_pred . astype ( int )))) w = clf . coef_ [ 0 ] b = clf . intercept_ [ 0 ] return ( X_train , X_test , y_train , y_test , y_pred , w , b , clf ) def plot ( X , y , xidx , yidx , xlabel , ylabel , w , b , y_pred ): N = 1000 r = 0.2 # Get the test data c = nd ( np . log1p ( y [:, 1 ])) x = nd ( X [:, xidx ]) y = nd ( X [:, yidx ]) # Find the limits xlims = ( np . min ( x ) * ( 1 - r ), np . max ( x ) * ( 1 + r )) ylims = ( np . min ( y ) * ( 1 - r ), np . max ( y ) * ( 1 + r )) # compute boundary line xx = np . linspace ( * xlims , len ( x )) yy = ( - xx * w [ xidx ] - b ) / w [ yidx ] X , Y = np . meshgrid ( np . linspace ( * xlims , N ), np . linspace ( * ylims , N )) YY = ( - X * w [ xidx ] - b ) / w [ yidx ] ############################################################### ax . set_xlim ( * xlims ) ax . set_ylim ( * ylims ) circle_m = y_pred == 1 square_m = y_pred == 0 circle_color = c [ circle_m ] square_color = c [ square_m ] ### Scatter plot of points circles = ax . scatter ( x [ circle_m ], y [ circle_m ], c = circle_color , s = 100 , marker = \"o\" , edgecolors = \"black\" , cmap = \"plasma\" , label = \"$+$ Viral RNA\" ) squares = ax . scatter ( x [ square_m ], y [ square_m ], c = square_color , s = 100 , marker = \"s\" , edgecolors = \"black\" , cmap = \"plasma\" , label = \"$-$ Viral RNA\" ) sc = ax . scatter ( x , y , c = c , s = 0 , edgecolors = \"black\" , cmap = \"plasma\" ) ### Plot boundary line # note that here we solve the above equation for y using the # coefficients and the intercept thresh = ax . plot ( xx , yy , linestyle = \"--\" , color = \"black\" , linewidth = 2 , label = \"Theshold\" ) ### Plot logistic function # Perpendicular from the line is the probability that a sample # has viral RNA. This function is the logistic function and has # the form f(x) = 1/(1+exp(-(x-x0))) but we only care about variation # perpendicular to the line so we use Y and YY Z = sigmoid ( Y - YY ) # Since we want probability of 1 to be above the line, we do 1-Z cs = ax . imshow ( Z , vmin = 0. , vmax = 1. , cmap = plt . cm . coolwarm , origin = 'lower' , extent = [ * xlims , * ylims ]) #### Colorbar for RNA amount plt . colorbar ( sc , label = \"log(Viral RNA molecules + 1)\" ) # Colorbar for Probability plt . colorbar ( cs , label = \"Probability of + Virus\" ) ############################################################### ## Prettying up the plot, adding pos = mpatches . Patch ( color = \"#D43F3A\" , label = 'Virus detected' ) neg = mpatches . Patch ( color = \"#3182bd\" , label = 'Virus not detected' ) handles , labels = ax . get_legend_handles_labels () order = [ 0 , 2 , 1 ] handles = [ handles [ idx ] for idx in order ]; handles . append ( neg ); handles . append ( pos ) ax . legend ( handles = handles [:: - 1 ], fontsize = fsize - 5 ) ax . set_xlabel ( \"log( {} +1) amplicon counts\" . format ( xlabel )) ax . set_ylabel ( \"log( {} +1) amplicon counts\" . format ( ylabel )) ax . set_xlabel ( \"log( {} +1) amplicon counts\" . format ( \"Spikein\" )) ax . set_ylabel ( \"log( {} +1) amplicon counts\" . format ( \"Viral\" )) ax . xaxis . set_major_formatter ( mpl . ticker . StrMethodFormatter ( ' {x:,.0f} ' )) ax . yaxis . set_major_formatter ( mpl . ticker . StrMethodFormatter ( ' {x:,.0f} ' )) plt . tight_layout ( h_pad = 1 ) ax . set_title ( \"Logistic regression classifier on test data\" ) return ax def plot_LOD_adjusted ( X_test , y_test , xlabel , ylabel , xidx , yidx , w , b , y_pred ): x = np . exp ( X_test [:, xidx ]) y = np . exp ( X_test [:, yidx ]) c = pd . Series ( y_pred ) . map ( cm ) xx = y_test [:, 1 ] # xx[xx==0] = 0.1 # yy = y*w[yidx] + x*(w[xidx]) yy = ( y ** w [ yidx ]) / ( x ** ( - w [ xidx ])) ax . scatter ( xx , yy , c = c ) ### Make the plot pretty ax . set_xscale ( \"symlog\" ) ax . set_yscale ( \"symlog\" ) # bc = ax.axhline(y=np.exp(-b), linestyle=\"--\", label=\"Log. reg. boundary\", color=\"k\") ax . set_xlabel ( r \"Viral RNA molecules\" ) ax . set_ylabel ( r \"( {} +1)^( {:,.2f} ) / ( {} +1)^( {:,.2f} )\" . format ( ylabel , w [ yidx ], xlabel , w [ xidx ])) ax . set_ylabel ( r \"( {} +1)^( {:,.2f} ) / ( {} +1)^( {:,.2f} )\" . format ( \"Viral\" , w [ yidx ], \"Spikein\" , w [ xidx ])) # legend pos = mpatches . Patch ( color = \"#D43F3A\" , label = 'Virus detected' ) neg = mpatches . Patch ( color = \"#3182bd\" , label = 'Virus not detected' ) ax . legend ( handles = [ pos , neg ]) ax . set_title ( \"Adjusted normalization based on logistic regression\" ) return ax def plot_LOD_normal ( X_test , y_test , xlabel , ylabel , xidx , yidx , w , b , y_pred ): x = np . exp ( X_test [:, xidx ]) y = np . exp ( X_test [:, yidx ]) c = pd . Series ( y_pred ) . map ( cm ) xx = y_test [:, 1 ] # xx[xx==0] = 0.1 yy = y / x ax . scatter ( xx , yy , c = c ) ### Make the plot pretty ax . set_xscale ( \"symlog\" ) ax . set_yscale ( \"symlog\" ) ax . set_xlabel ( r \"Viral RNA molecules\" ) ax . set_ylabel ( r \"( {} +1) / ( {} +1))\" . format ( ylabel , xlabel )) ax . set_ylabel ( r \"( {} +1) / ( {} +1))\" . format ( \"Viral\" , \"Spikein\" )) # legend pos = mpatches . Patch ( color = \"#D43F3A\" , label = 'Virus detected' ) neg = mpatches . Patch ( color = \"#3182bd\" , label = 'Virus not detected' ) ax . legend ( handles = [ pos , neg ]) ax . set_title ( \"Standard normalization\" ) return ax cm = { 1 : \"#D43F3A\" , 0 : \"#3182bd\" } fsize = 20 plt . rcParams . update ({ 'font.size' : fsize }) % config InlineBackend . figure_format = 'retina'","title":"Obtain diagnostic results from the adata"},{"location":"tutorials/diagnostic/#load-results","text":"1 adata = anndata . read_h5ad ( \"BLCSBGLKP_2020/data/kb/adata.h5ad\" )","title":"Load results"},{"location":"tutorials/diagnostic/#diagnostic-testing","text":"We restrict our analysis to Plate1 HEK293 N ATCC_RNA We also drop the S genes since they were used in plate 2 only.","title":"Diagnostic testing"},{"location":"tutorials/diagnostic/#we-restrict-our-diagnostic-analysis-to-plate1-hek293-n-atcc_rna","text":"Other examples are shown after. 1 # Plate1 HEK293 N ATCC_RNA 1 2 3 4 5 6 7 8 9 10 11 12 13 a = np . logical_and (( adata . obs . plate == \"Plate1\" ) . values , ( adata . obs . lysate == \"HEK293\" ) . values ) b = np . logical_and ( a , adata . obs . Twist . values == 0 ) c = np . logical_and ( b , adata . obs . ATCC_viral . values == 0 ) data = adata [ b ] data . obs [ \"sick\" ] = ( data . obs . ATCC_RNA > 0 ) . astype ( int ) data = data [:, np . logical_or ( ~ data . var . gene . str . contains ( \"_S\" ), data . var . gene . str . contains ( \"RPP30\" ))] #data = data[:,data.var.sort_values(\"gene\").index] X = np . log1p ( data . layers [ \"raw\" ]) y1 = nd ( data . obs . sick . values . astype ( int )) y2 = nd ( data . obs . ATCC_RNA . values ) Trying to set attribute `.obs` of view, copying. We split our data in half. We train a logistic regression model on the training half, and test out our model on the testing half. For the sake of downstream plotting, we append the Twist RNA values to the real classificaation for each sample to make a sample x 2 matrix. This results in y_test having two columns. When splitting the data into training and testing the Twist RNA values associated with the split samples are retained. Since n_samples > n_genes we set dual=False in the logistic regresion classification since we are not interested in solving using the dual formulation of the regularization. The equation of the line is $w_1 x + w_2 y = b$. 1 data View of AnnData object with n_obs \u00d7 n_vars = 140 \u00d7 5 obs : 'bcs' , 'ecs' , 'cnt' , 'plate' , 'well' , 'lysate' , 'Twist' , 'ATCC_RNA' , 'ATCC_viral' , 'Twist_bool' , 'ATCC_viral_bool' , 'ATCC_RNA_bool' , 'sick' var : 'gene' obsm : 'X_pca' layers : 'log1p' , 'norm' , 'raw' , 'scale' 1 data . var .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } gene 0 N1 1 N1_spikein 2 RPP30 3 S2 4 S2_spikein 1 ( X_train , X_test , y_train , y_test , y_pred , w , b , clf ) = main ( X , y1 , y2 ) Score : 0.9571 Precision : 1.0000 Recall : 0.9388 1 2 3 4 5 6 7 8 fig , ax = plt . subplots ( figsize = ( 15 , 10 )) xlabel , ylabel = ( \"N1_spikein\" , \"N1\" ) xidx , yidx = ( np . where ( data . var . gene . values == xlabel )[ 0 ][ 0 ], np . where ( data . var . gene . values == ylabel )[ 0 ][ 0 ]) plot ( X_test , y_test , xidx , yidx , xlabel , ylabel , w , b , y_pred ) plt . show ()","title":"We restrict our diagnostic analysis to Plate1 HEK293  N   ATCC_RNA"},{"location":"tutorials/diagnostic/#examine-relative-counts","text":"1 2 3 4 5 6 7 8 fig , ax = plt . subplots ( figsize = ( 10 , 10 )) xlabel , ylabel = ( \"N1_spikein\" , \"N1\" ) xidx , yidx = ( np . where ( data . var . gene . values == xlabel )[ 0 ][ 0 ], np . where ( data . var . gene . values == ylabel )[ 0 ][ 0 ]) plot_LOD_normal ( X_test , y_test , xlabel , ylabel , xidx , yidx , w , b , y_pred ) plt . show ()","title":"Examine relative counts"},{"location":"tutorials/diagnostic/#adjusted-relative-abundances","text":"The logistic regression was performed on the log(X+1) counts and the train/test/split gives back matrices that are log(X+1). In order to make plotting nicer (ie loglog scale axis), we exponentiate the matrices. Given $X_l = \\log(X+1)$ we wish to plot $\\frac{(Y+1)^{w_2}}{(X+1)^{w_1}}$ vs the amount of Twist RNA. We can plot $\\frac{(Y+1)^{w_2}}{(X+1)^{w_1}} = \\frac{exp(Y_l)^{w_2}}{exp(X_l)^{w_1}}$ vs the amount of Twist RNA. 1 2 3 4 5 6 7 8 fig , ax = plt . subplots ( figsize = ( 10 , 10 )) xlabel , ylabel = ( \"N1_spikein\" , \"N1\" ) xidx , yidx = ( np . where ( data . var . gene . values == xlabel )[ 0 ][ 0 ], np . where ( data . var . gene . values == ylabel )[ 0 ][ 0 ]) plot_LOD_adjusted ( X_test , y_test , xlabel , ylabel , xidx , yidx , w , b , y_pred ) plt . show () 1 2 print ( \"Precision: {:,.4f} \" . format ( metrics . precision_score ( y_test [:, 0 ], y_pred ))) print ( \"Recall: {:,.4f} \" . format ( metrics . recall_score ( y_test [:, 0 ], y_pred ))) Precision : 1.0000 Recall : 0.9388","title":"Adjusted relative abundances"},{"location":"tutorials/diagnostic/#make-these-plots-for-all-hek-experiments","text":"1 2 3 4 5 6 exp = [ ( \"Plate1\" , \"HEK293\" , \"N1\" , \"Twist\" ), ( \"Plate1\" , \"HEK293\" , \"N1\" , \"ATCC_RNA\" ), ( \"Plate2\" , \"HEK293\" , \"S2\" , \"Twist\" ), ( \"Plate2\" , \"HEK293\" , \"S2\" , \"ATCC_RNA\" ), ] 1 adata . var .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } gene 0 N1 1 N1_spikein 2 RPP30 3 S2 4 S2_spikein 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 adata = adata [:, adata . var . sort_values ( \"gene\" ) . index ] XXX = np . asarray ( adata . layers [ \"raw\" ]) plot_values = [] for ( p , l , g , c ) in exp : pmask = adata . obs . plate . values == p cmask = adata . obs [ c + \"_bool\" ] . values lmask = adata . obs . lysate . values == l m = np . logical_and ( np . logical_and ( pmask , cmask ), lmask ) vm = np . logical_or ( adata . var . gene . str . contains ( g ), adata . var . gene . str . contains ( \"RPP30\" )) . values gene_labels = adata . var . gene . values XX = XXX [ m ][:, vm ] X = np . log1p ( XX ) y1 = nd (( adata . obs [ m ][ c ] > 0 ) . astype ( int )) y2 = nd ( adata . obs [ m ][ c ] . values ) print ( \" {} \\t {} \\t {} \\t {} \" . format ( p , l , g [ 0 ], c )) ( X_train , X_test , y_train , y_test , y_pred , w , b , clf ) = main ( X , y1 , y2 ) ########################################################## fig , ax = plt . subplots ( figsize = ( 15 , 10 )) xlabel , ylabel = ( g + \"_spikein\" , g ) xidx , yidx = ( np . where ( gene_labels [ vm ] == xlabel )[ 0 ][ 0 ], np . where ( gene_labels [ vm ] == ylabel )[ 0 ][ 0 ]) plot ( X_test , y_test , xidx , yidx , xlabel , ylabel , w , b , y_pred ) ax . set_title ( \"Classifier: {} {} {} \" . format ( p , g [ 0 ], c )) plt . savefig ( \"./log_reg_ {} _ {} _ {} .png\" . format ( p , g , c ), bbox_inches = 'tight' , dpi = 300 ) plt . show () ########################################################## fig , ax = plt . subplots ( figsize = ( 10 , 10 )) plot_LOD_normal ( X_test , y_test , xlabel , ylabel , xidx , yidx , w , b , y_pred ) ax . set_title ( \"Standard curve: {} {} {} \" . format ( p , g [ 0 ], c )) #plt.savefig(\"./figs/lod_norm_{}_{}_{}.png\".format(p, g, c),bbox_inches='tight', dpi=300) plt . show () ########################################################## fig , ax = plt . subplots ( figsize = ( 10 , 10 )) plot_LOD_adjusted ( X_test , y_test , xlabel , ylabel , xidx , yidx , w , b , y_pred ) ax . set_title ( \"Adjusted standard curve: {} {} {} \" . format ( p , g [ 0 ], c )) #plt.savefig(\"./figs/lod_adj_{}_{}_{}.png\".format(p, g, c),bbox_inches='tight', dpi=300) plt . show () Plate1 HEK293 N Twist Score: 0.8333 Precision: 0.7391 Recall: 0.8947 Plate1 HEK293 N ATCC_RNA Score: 0.9571 Precision: 1.0000 Recall: 0.9388 Plate2 HEK293 S Twist Score: 0.9375 Precision: 0.9000 Recall: 0.9474 Plate2 HEK293 S ATCC_RNA Score: 0.8857 Precision: 0.9767 Recall: 0.8571","title":"Make these plots for all HEK experiments"},{"location":"tutorials/diagnostic/#diagnostic-results-are-reported-as-probabilities","text":"1 pd . DataFrame ( clf . predict_proba ( X_test ), columns = [ \"- virus\" , \"+ virus\" ]) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } - virus + virus 0 0.988534 0.011466 1 0.005457 0.994543 2 0.975508 0.024492 3 0.005474 0.994526 4 0.057123 0.942877 ... ... ... 65 0.003317 0.996683 66 0.053892 0.946108 67 0.119947 0.880053 68 0.305283 0.694717 69 0.020065 0.979935 70 rows \u00d7 2 columns 1","title":"Diagnostic results are reported as probabilities"},{"location":"tutorials/terminal_interacting_with_fastq_files/","text":"Interacting with FASTQ files \u00b6 FASTQ files are text files that contain biological sequences, usually nucleotides, and their associated quality scores. The quality score is a measure of how accurate the base-call is for each letter in the sequence. For more information please see the wikipedia entry . tl;dr In this tutorial we introduce ways to interact with FASTQ files by the command line. The curl command \u00b6 We will use the curl command to download FASTQ files to our machine. curl is a command line tool that allows us to download files. It takes a URL as an argument and downloads the file to your local computer in the current directory. For most cases when downloading data with curl we will use the following syntax: 1 $ curl -Ls -o outputfile.txt http://www.somewebsite.com/myfile.txt Where the -L tells the command to follow \"redirects\" in case the file as been moved, -s tells the command to be silent and the -o tells the command the name of the file to be saved. Downloading FASTQ files \u00b6 FASTQ files usually come in pairs. They are coloquially called \"read 1\" and \"read 2\". This naming refers to the order in which the molecules were sequenced. We won't cover the many ways in which FASTQ files can be generated in this tutorial but for more details please check out these resources: Illumina documentation , Next Generation Sequencing Core @UPenn . 1 2 !curl -Ls -o read1.fastq https://caltech.box.com/shared/static/fh81mkceb8ydwma3tlrqfgq22z4kc4nt.gz !curl -Ls -o read2.fastq https://caltech.box.com/shared/static/ycxkluj5my7g3wiwhyq3vhv71mw5gmj5.gz 1 !ls -lht total 434M -rw-r--r-- 1 root root 247M Jan 4 23:49 read2.fastq -rw-r--r-- 1 root root 188M Jan 4 23:48 read1.fastq drwxr-xr-x 1 root root 4.0K Dec 21 17:29 sample_data Interacting with FASTQ files \u00b6 FASTQ files can be quite large, often on the order of tens to hundreds of gigabytes, therefore it is impractical to open them up and view them in a text editor. For this reason FASTQ files are often \"compressed\" to save storage space. The type of compression is colloquially called \"gzip\" compression to refer to the command line tool that compresses files. Useful commands \u00b6 The gzip command and the gunzip command \u00b6 Often times FASTQ files end with .fastq.gz . This means that they have been compressed with the gzip command. They can be decompressed them with the gunzip command. Though most of the time we don't want to decompress them since that would require a lot of space. The syntax for decompressing and compressing a file in most cases will look like the following: 1 2 $ gunzip file.fastq.gz $ gzip file.fastq Our files are currently decompressed. Let's see how much space we save by compressing them. 1 2 3 4 !ls -lht !gzip read1.fastq !gzip read2.fastq !ls -lht total 434M -rw-r--r-- 1 root root 247M Jan 4 23:49 read2.fastq -rw-r--r-- 1 root root 188M Jan 4 23:48 read1.fastq drwxr-xr-x 1 root root 4.0K Dec 21 17:29 sample_data total 74M -rw-r--r-- 1 root root 47M Jan 4 23:49 read2.fastq.gz -rw-r--r-- 1 root root 28M Jan 4 23:48 read1.fastq.gz drwxr-xr-x 1 root root 4.0K Dec 21 17:29 sample_data The read1 FASTQ file went from 188 Megabytes in size (decompressed, read1.fastq ) to 28 Megabytes in size (compressed, read1.fastq.gz ) and the read2 FASTQ file went from 247 Megabytes (decompressed, read2.fastq ) to 47 Megabytes (compressed, read2.fastq.gz ). The read1 file was compressed by a factor of 6.7 and the read2 file was compressed by a factor of 5.2. The zcat command \u00b6 Since we almost always want to keep our FASTQ files compressed but we still want to be able to read them we will use a modified version of the cat command but for files that have been compressed with gzip . The zcat command does exactly the same thing to a file as the cat , namely it prints the contents of the file to the screen. The difference, however is that the zcat command expects a compressed file. The syntax looks like this: 1 $ zcat file.fastq.gz Reading FASTQ files \u00b6 If we simply use zcat as above it will print the whole file to the screen so instead we \"pipe\" the output of the zcat command to the head command. We don't conver pipes in this video but there are a lot of great resources covering them. Here is a nice video explaining pipes. The head command just stops the process of printing after a certain number of lines. The default is 10 lines. 1 !zcat read1.fastq.gz | head @SRR8611943.1 NS500272:478:HVL5HBGX5:1:11101:9611:1040 length=26 ACATCNGTCGAGAACGATCGTGTCCG +SRR8611943.1 NS500272:478:HVL5HBGX5:1:11101:9611:1040 length=26 AAAAA#EEEEEEEEEEEEEEEEEEEE @SRR8611943.2 NS500272:478:HVL5HBGX5:1:11101:20079:1043 length=26 TCAGCNCCAACTGCTAGTCTTTCCCT +SRR8611943.2 NS500272:478:HVL5HBGX5:1:11101:20079:1043 length=26 AAAAA#EEEEEE6EEEEEEEEEEEEE @SRR8611943.3 NS500272:478:HVL5HBGX5:1:11101:10651:1043 length=26 TGAAANATCACGCGGTTCATCAGTAG We can change the number of lines printed by head by specifying a -n option: 1 !zcat read1.fastq.gz | head -n 4 @SRR8611943.1 NS500272:478:HVL5HBGX5:1:11101:9611:1040 length=26 ACATCNGTCGAGAACGATCGTGTCCG +SRR8611943.1 NS500272:478:HVL5HBGX5:1:11101:9611:1040 length=26 AAAAA#EEEEEEEEEEEEEEEEEEEE FASTQ Format \u00b6 Every four lines in a FASTQ file represent one molecule that was sequenced. 1 2 3 4 @SRR8611943.1 NS500272:478:HVL5HBGX5:1:11101:9611:1040 length=26 ACATCNGTCGAGAACGATCGTGTCCG +SRR8611943.1 NS500272:478:HVL5HBGX5:1:11101:9611:1040 length=26 AAAAA#EEEEEEEEEEEEEEEEEEEE The first line is the molecule identifier, the second line is the actual sequence of the molecule, the third line starts with a + sign and provides optional information, and the fourth line is the quality score of the sequence. Note that the quality score must be the same length of the molecule. To learn more about quality scores please check out the Illumina documentation . Counting the number of molecules (reads) \u00b6 A common task for bioinformaticians is to count the number of reads (also known as the number of molecules) in a FASTQ file. This means we need to count the number of lines in the FASTQ file and then divide by four, since a read is represented by four lines. We will use the wc command to count the number of lines in a file. The wc command is a commandline tool to count the number of words, characters, and lines in a file. The syntax for counting lines in a file is the following: 1 $ wc -l myfile.txt We will use the wc command to count the number of lines in the FASTQ file and then we will divide by four to get the number of reads. 1 2 !zcat read1.fastq.gz | wc -l !zcat read2.fastq.gz | wc -l 4000000 4000000 Both read1 and read2 have 4,000,000 lines, this means that they have 1 million reads. For \"paired-end\" sequencing data where read 1 and read 2 are given, both FASTQ files will always have the same number of reads since sequneces from a single molecule are represented in both files. Finding an exact sequence \u00b6 Another common task for bioinformaticians is to find an exact sequence in the FASTQ files. We will use the grep command along with the zcat command. The grep command is a commandline tool that enables searching. The grep command can get complicated but most use cases can be covered by the following syntax: 1 $ grep \"find this\" myfile.txt Let's find the sequence ATTAGGAGCCG in read1.fastq.gz . 1 !zcat read2.fastq.gz | grep \"ATTAGGAGCCG\" GAAGATGTTGTCGTGGATACTGAAATGCGTCGTCAAAAATTAGGAGCCGTTCTTTTG GTCAAAAATTAGGAGCCGTTCTTTTGAAGACTCTTGTTTCTCTTGGAAAGTCTCTCG GCGTCGTCAAAAATTAGGAGCCGTTGGTTTGAAGAATCTTTTTTCTAATGGAAAGTG GCGTCGTCAAAAATTAGGAGCCGTTCTTTTGAAGACTCTTGTTTCTCTTGGAAAGTC CAAAAATTAGGAGCCGTTCTTTTGAAGACTCTTGTTTCTCTTGGAAAGTCTCTCGGA Enumerating lines of a FASTQ file \u00b6 In the above example we found five reads that contain our sequence of interest but we don't know what line number they came from. We can figure this out by using the nl command. The nl command is a commandline tool to add line numbers to the file. The syntax is as follows: 1 $ nl file.txt Let's find out the line numbers where we found our sequence. 1 !zcat read2.fastq.gz | nl | grep \"ATTAGGAGCCG\" 535046 GAAGATGTTGTCGTGGATACTGAAATGCGTCGTCAAAAATTAGGAGCCGTTCTTTTG 745522 GTCAAAAATTAGGAGCCGTTCTTTTGAAGACTCTTGTTTCTCTTGGAAAGTCTCTCG 818990 GCGTCGTCAAAAATTAGGAGCCGTTGGTTTGAAGAATCTTTTTTCTAATGGAAAGTG 1654078 GCGTCGTCAAAAATTAGGAGCCGTTCTTTTGAAGACTCTTGTTTCTCTTGGAAAGTC 1956810 CAAAAATTAGGAGCCGTTCTTTTGAAGACTCTTGTTTCTCTTGGAAAGTCTCTCGGA Summary \u00b6 In this tutorial we learned how to interact with FASTQ files using built in shell commands to perform simple tasks. 1","title":"Terminal interacting with fastq files"},{"location":"tutorials/terminal_interacting_with_fastq_files/#interacting-with-fastq-files","text":"FASTQ files are text files that contain biological sequences, usually nucleotides, and their associated quality scores. The quality score is a measure of how accurate the base-call is for each letter in the sequence. For more information please see the wikipedia entry . tl;dr In this tutorial we introduce ways to interact with FASTQ files by the command line.","title":"Interacting with FASTQ files"},{"location":"tutorials/terminal_interacting_with_fastq_files/#the-curl-command","text":"We will use the curl command to download FASTQ files to our machine. curl is a command line tool that allows us to download files. It takes a URL as an argument and downloads the file to your local computer in the current directory. For most cases when downloading data with curl we will use the following syntax: 1 $ curl -Ls -o outputfile.txt http://www.somewebsite.com/myfile.txt Where the -L tells the command to follow \"redirects\" in case the file as been moved, -s tells the command to be silent and the -o tells the command the name of the file to be saved.","title":"The curl command"},{"location":"tutorials/terminal_interacting_with_fastq_files/#downloading-fastq-files","text":"FASTQ files usually come in pairs. They are coloquially called \"read 1\" and \"read 2\". This naming refers to the order in which the molecules were sequenced. We won't cover the many ways in which FASTQ files can be generated in this tutorial but for more details please check out these resources: Illumina documentation , Next Generation Sequencing Core @UPenn . 1 2 !curl -Ls -o read1.fastq https://caltech.box.com/shared/static/fh81mkceb8ydwma3tlrqfgq22z4kc4nt.gz !curl -Ls -o read2.fastq https://caltech.box.com/shared/static/ycxkluj5my7g3wiwhyq3vhv71mw5gmj5.gz 1 !ls -lht total 434M -rw-r--r-- 1 root root 247M Jan 4 23:49 read2.fastq -rw-r--r-- 1 root root 188M Jan 4 23:48 read1.fastq drwxr-xr-x 1 root root 4.0K Dec 21 17:29 sample_data","title":"Downloading FASTQ files"},{"location":"tutorials/terminal_interacting_with_fastq_files/#interacting-with-fastq-files_1","text":"FASTQ files can be quite large, often on the order of tens to hundreds of gigabytes, therefore it is impractical to open them up and view them in a text editor. For this reason FASTQ files are often \"compressed\" to save storage space. The type of compression is colloquially called \"gzip\" compression to refer to the command line tool that compresses files.","title":"Interacting with FASTQ files"},{"location":"tutorials/terminal_interacting_with_fastq_files/#useful-commands","text":"","title":"Useful commands"},{"location":"tutorials/terminal_interacting_with_fastq_files/#the-gzip-command-and-the-gunzip-command","text":"Often times FASTQ files end with .fastq.gz . This means that they have been compressed with the gzip command. They can be decompressed them with the gunzip command. Though most of the time we don't want to decompress them since that would require a lot of space. The syntax for decompressing and compressing a file in most cases will look like the following: 1 2 $ gunzip file.fastq.gz $ gzip file.fastq Our files are currently decompressed. Let's see how much space we save by compressing them. 1 2 3 4 !ls -lht !gzip read1.fastq !gzip read2.fastq !ls -lht total 434M -rw-r--r-- 1 root root 247M Jan 4 23:49 read2.fastq -rw-r--r-- 1 root root 188M Jan 4 23:48 read1.fastq drwxr-xr-x 1 root root 4.0K Dec 21 17:29 sample_data total 74M -rw-r--r-- 1 root root 47M Jan 4 23:49 read2.fastq.gz -rw-r--r-- 1 root root 28M Jan 4 23:48 read1.fastq.gz drwxr-xr-x 1 root root 4.0K Dec 21 17:29 sample_data The read1 FASTQ file went from 188 Megabytes in size (decompressed, read1.fastq ) to 28 Megabytes in size (compressed, read1.fastq.gz ) and the read2 FASTQ file went from 247 Megabytes (decompressed, read2.fastq ) to 47 Megabytes (compressed, read2.fastq.gz ). The read1 file was compressed by a factor of 6.7 and the read2 file was compressed by a factor of 5.2.","title":"The gzip command and the gunzip command"},{"location":"tutorials/terminal_interacting_with_fastq_files/#the-zcat-command","text":"Since we almost always want to keep our FASTQ files compressed but we still want to be able to read them we will use a modified version of the cat command but for files that have been compressed with gzip . The zcat command does exactly the same thing to a file as the cat , namely it prints the contents of the file to the screen. The difference, however is that the zcat command expects a compressed file. The syntax looks like this: 1 $ zcat file.fastq.gz","title":"The zcat command"},{"location":"tutorials/terminal_interacting_with_fastq_files/#reading-fastq-files","text":"If we simply use zcat as above it will print the whole file to the screen so instead we \"pipe\" the output of the zcat command to the head command. We don't conver pipes in this video but there are a lot of great resources covering them. Here is a nice video explaining pipes. The head command just stops the process of printing after a certain number of lines. The default is 10 lines. 1 !zcat read1.fastq.gz | head @SRR8611943.1 NS500272:478:HVL5HBGX5:1:11101:9611:1040 length=26 ACATCNGTCGAGAACGATCGTGTCCG +SRR8611943.1 NS500272:478:HVL5HBGX5:1:11101:9611:1040 length=26 AAAAA#EEEEEEEEEEEEEEEEEEEE @SRR8611943.2 NS500272:478:HVL5HBGX5:1:11101:20079:1043 length=26 TCAGCNCCAACTGCTAGTCTTTCCCT +SRR8611943.2 NS500272:478:HVL5HBGX5:1:11101:20079:1043 length=26 AAAAA#EEEEEE6EEEEEEEEEEEEE @SRR8611943.3 NS500272:478:HVL5HBGX5:1:11101:10651:1043 length=26 TGAAANATCACGCGGTTCATCAGTAG We can change the number of lines printed by head by specifying a -n option: 1 !zcat read1.fastq.gz | head -n 4 @SRR8611943.1 NS500272:478:HVL5HBGX5:1:11101:9611:1040 length=26 ACATCNGTCGAGAACGATCGTGTCCG +SRR8611943.1 NS500272:478:HVL5HBGX5:1:11101:9611:1040 length=26 AAAAA#EEEEEEEEEEEEEEEEEEEE","title":"Reading FASTQ files"},{"location":"tutorials/terminal_interacting_with_fastq_files/#fastq-format","text":"Every four lines in a FASTQ file represent one molecule that was sequenced. 1 2 3 4 @SRR8611943.1 NS500272:478:HVL5HBGX5:1:11101:9611:1040 length=26 ACATCNGTCGAGAACGATCGTGTCCG +SRR8611943.1 NS500272:478:HVL5HBGX5:1:11101:9611:1040 length=26 AAAAA#EEEEEEEEEEEEEEEEEEEE The first line is the molecule identifier, the second line is the actual sequence of the molecule, the third line starts with a + sign and provides optional information, and the fourth line is the quality score of the sequence. Note that the quality score must be the same length of the molecule. To learn more about quality scores please check out the Illumina documentation .","title":"FASTQ Format"},{"location":"tutorials/terminal_interacting_with_fastq_files/#counting-the-number-of-molecules-reads","text":"A common task for bioinformaticians is to count the number of reads (also known as the number of molecules) in a FASTQ file. This means we need to count the number of lines in the FASTQ file and then divide by four, since a read is represented by four lines. We will use the wc command to count the number of lines in a file. The wc command is a commandline tool to count the number of words, characters, and lines in a file. The syntax for counting lines in a file is the following: 1 $ wc -l myfile.txt We will use the wc command to count the number of lines in the FASTQ file and then we will divide by four to get the number of reads. 1 2 !zcat read1.fastq.gz | wc -l !zcat read2.fastq.gz | wc -l 4000000 4000000 Both read1 and read2 have 4,000,000 lines, this means that they have 1 million reads. For \"paired-end\" sequencing data where read 1 and read 2 are given, both FASTQ files will always have the same number of reads since sequneces from a single molecule are represented in both files.","title":"Counting the number of molecules (reads)"},{"location":"tutorials/terminal_interacting_with_fastq_files/#finding-an-exact-sequence","text":"Another common task for bioinformaticians is to find an exact sequence in the FASTQ files. We will use the grep command along with the zcat command. The grep command is a commandline tool that enables searching. The grep command can get complicated but most use cases can be covered by the following syntax: 1 $ grep \"find this\" myfile.txt Let's find the sequence ATTAGGAGCCG in read1.fastq.gz . 1 !zcat read2.fastq.gz | grep \"ATTAGGAGCCG\" GAAGATGTTGTCGTGGATACTGAAATGCGTCGTCAAAAATTAGGAGCCGTTCTTTTG GTCAAAAATTAGGAGCCGTTCTTTTGAAGACTCTTGTTTCTCTTGGAAAGTCTCTCG GCGTCGTCAAAAATTAGGAGCCGTTGGTTTGAAGAATCTTTTTTCTAATGGAAAGTG GCGTCGTCAAAAATTAGGAGCCGTTCTTTTGAAGACTCTTGTTTCTCTTGGAAAGTC CAAAAATTAGGAGCCGTTCTTTTGAAGACTCTTGTTTCTCTTGGAAAGTCTCTCGGA","title":"Finding an exact sequence"},{"location":"tutorials/terminal_interacting_with_fastq_files/#enumerating-lines-of-a-fastq-file","text":"In the above example we found five reads that contain our sequence of interest but we don't know what line number they came from. We can figure this out by using the nl command. The nl command is a commandline tool to add line numbers to the file. The syntax is as follows: 1 $ nl file.txt Let's find out the line numbers where we found our sequence. 1 !zcat read2.fastq.gz | nl | grep \"ATTAGGAGCCG\" 535046 GAAGATGTTGTCGTGGATACTGAAATGCGTCGTCAAAAATTAGGAGCCGTTCTTTTG 745522 GTCAAAAATTAGGAGCCGTTCTTTTGAAGACTCTTGTTTCTCTTGGAAAGTCTCTCG 818990 GCGTCGTCAAAAATTAGGAGCCGTTGGTTTGAAGAATCTTTTTTCTAATGGAAAGTG 1654078 GCGTCGTCAAAAATTAGGAGCCGTTCTTTTGAAGACTCTTGTTTCTCTTGGAAAGTC 1956810 CAAAAATTAGGAGCCGTTCTTTTGAAGACTCTTGTTTCTCTTGGAAAGTCTCTCGGA","title":"Enumerating lines of a FASTQ file"},{"location":"tutorials/terminal_interacting_with_fastq_files/#summary","text":"In this tutorial we learned how to interact with FASTQ files using built in shell commands to perform simple tasks. 1","title":"Summary"},{"location":"tutorials/test2/","text":"An introduction to single-cell RNA-seq \u00b6 Written by Sina Booeshaghi and Lior Pachter . Based on material taught in Caltech course Bi/BE/CS183 by Lior Pachter and Matt Thomson, with contributions from Sina Booeshaghi, Lambda Lu, Jialong Jiang, Eduardo Beltrame, Jase Gehring, Ingileif Hallgr\u00edmsd\u00f3ttir and Valentine Svensson. \u00b6 *Division of Biology and Biological Engineering, California Institute of Technology \u00b6 The rapid development of single-cell genomics methods starting in 2009 has created unprecedented opportunity for highly resolved measurements of cellular states. Among such methods, single-cell RNA-seq (scRNA-seq) is having a profound impact on biology. Here we introduce some of the key concepts of single-cell RNA-seq technologies, with a focus on droplet based methods. To learn how to pre-process and analyze single-cell RNA-seq explore the following Google Colab notebooks that explain how to go from reads to results: Pre-processing and quality control [ Python , R ] Getting started with analysis [ Python , R ] Building and annotating an atlas [ Python , R ] The kallistobus.tools tutorials site has a extensive list of tutorials and vignettes on single-cell RNA-seq. Setup \u00b6 This notebook is a \"living document\". It downloads data and performs computations. As such it requires the installation of some python packages, which are installed with the commands below. In addition to running on Google Colab, the notebook can be downloaded and run locally on any machine which has python3 installed. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 #@title Install packages %%capture !pip install matplotlib !pip install scikit-learn !pip install numpy !pip install scipy !pip install anndata import numpy as np import matplotlib.cm as cm import matplotlib.pyplot as plt import matplotlib.colors as mplcol import matplotlib.font_manager import matplotlib as mpl import pandas as pd import io import anndata from scipy.stats import binom from scipy.stats import poisson from scipy.sparse import csr_matrix from scipy.io import mmread from sklearn import linear_model from IPython.display import HTML from mizani.breaks import date_breaks from mizani.formatters import date_format # Only pandas >= v0.25.0 supports column names with spaces in querys import plotnine as p import requests import warnings import colorsys warnings.filterwarnings(\"ignore\") # plotnine has a lot of MatplotlibDeprecationWarning's import seaborn as sns sns.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 2.5}) fsize=20 plt.rcParams.update({'font.size': fsize}) %config InlineBackend.figure_format = 'retina' Motivation \u00b6 The goal of single-cell transcriptomics is to measure the transcriptional states of large numbers of cells simultaneously. The input to a scRNA-seq method is a collection of cells, possibly from intact tissue, or in dissociated form. Formally, the desired output is a transcripts x cells or genes x cells matrix that describes, for each cell, the abundance of its constituent transcripts or genes. More generally, single-cell genomics methods seek to measure not just transcriptional state, but other modalities in cells, e.g. protein abundances, epigenetic states, cellular morphology, etc. The ideal single-cell technology should thus: Be universal in terms of cell size, type and state. Perform in situ measurements. Have no minimum input requirements. Assay every cell, i.e. have a 100% capture rate . Detect every transcript in every cell, i.e. have 100% sensitivity . Identify individual transcripts by their full-length sequence . Assign transcripts correctly to cells, e.g. no doublets . Be compatible with additional multimodal measurements . Be cost effective per cell. Be easy to use . Be open source so that it is transparent, and results from it reproducible. There is no method satisfying all of these requirements, however progress has been rapid. The development of single-cell RNA-seq technologies and their adoption by biologists, has been remarkable. Svensson et al. 2019 describes a database of articles which present single-cell RNA-seq experiments, and the graph below, rendered from the current version of the database , makes clear the exponential growth in single-cell transcriptomics: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 #@title Growth of single-cell RNA-seq df = pd.read_csv('http://nxn.se/single-cell-studies/data.tsv', sep='\\t') # converts string to date format, can only be run once! df['Date'] = pd.to_datetime(df['Date'], format='%Y%m%d') # converts string of reported cells total to float, can only be run once! df['Reported cells total'] = df['Reported cells total'].str.replace(',', '').map(float) # plot number of studies over time fig, ax = plt.subplots(figsize=(12, 5)) papers = pd.read_csv('http://nxn.se/single-cell-studies/data.tsv', sep='\\t') papers['Datetime'] = pd.to_datetime(papers['Date'], format='%Y%m%d') papers = papers.sort_values(\"Date\") papers[\"count\"] = 1 x = papers.Datetime y = papers[\"count\"].groupby(papers.Datetime.dt.time).cumsum() ax.plot(x, y, color=\"k\") ax.set_xlabel(\"Date\") ax.set_ylabel(\"Cumulative number of studies\") plt.show() There are many different scRNA-seq technologies in use and under development, but broadly they fall into a few categories - well-based methods (e.g. Fluidigm SMARTer C1, Smart-seq2) - droplet-based methods (e.g. Drop-seq, InDrops, 10X Genomics Chromium) - spatial transcriptomics approaches (e.g. MERFISH, SEQFISH) At the time of initial writing of this document (2019), droplet-based approaches have become popular due to their relative low-cost, easy of use, and scalability. This is evident in a breakdown of articles by technology used: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 #@title Technologies used def tidy_split(df, column, sep='|', keep=False): indexes = list() new_values = list() df = df.dropna(subset=[column]) for i, presplit in enumerate(df[column].astype(str)): values = presplit.split(sep) if keep and len(values) > 1: indexes.append(i) new_values.append(presplit) for value in values: indexes.append(i) new_values.append(value) new_df = df.iloc[indexes, :].copy() new_df[column] = new_values return new_df ts = pd.Timestamp tdf = tidy_split(df, 'Technique', ' & ') t_dict = {k: k for k in tdf['Technique'].value_counts().head(5).index} tdf['Technique'] = tdf['Technique'].map(lambda s: t_dict.get(s, 'Other')) techs = list( tdf['Technique'] .value_counts() .sort_index() .index .difference(['Other']) ) techs.append('Other') tdf['Technique'] = ( pd.Categorical( tdf['Technique'], categories=techs, ordered=True ) ) def desaturate(color, prop): # Check inputs # if not 0 <= prop <= 1: # raise ValueError(\"prop must be between 0 and 1\") # Get rgb tuple rep rgb = mplcol.colorConverter.to_rgb(color) # Convert to hls h, l, s = colorsys.rgb_to_hls(*rgb) # Desaturate the saturation channel # l *= prop l = 0.8 # Convert back to rgb new_color = colorsys.hls_to_rgb(h, l, s) hex_color = '#{:02x}{:02x}{:02x}'.format(*map(lambda c: int(c * 255), new_color)) return hex_color # lighten matplotlib default colors clrs = list(map(lambda c: desaturate(c, 1.2), ['C0', 'C1', 'C2', 'C3', 'C4', 'black'])) #### Plot number of studies per month by technique per_month = ( tdf .groupby('Technique') .resample('1M', on='Date') .count()['DOI'] .reset_index() ) p.options.figure_size = (9, 2) fig = ( p.ggplot( p.aes(x='Date', y='DOI', fill='Technique'), data=per_month.query('Date > @ts(\"20130101T010101\")') ) + p.geom_bar(stat='identity', color='grey') + p.theme_minimal(base_family='DejaVu Sans') + p.scale_x_datetime( breaks=date_breaks('1 years'), labels=date_format('%Y') ) + p.labs(y='Number of studies') + p.scale_fill_manual(clrs) ) fig <ggplot: (-9223363288449985206)> We therefore restrict this exposition to droplet-based technologies. Droplet-based methods \u00b6 Droplet based single-cell RNA-seq methods were popularized by a pair of papers published concurrently in 2015: - Macosko et al., Highly parallel genome-wide expression profiling of individual cells using nanoliter droplets , 2015. DOI:10.1016/j.cell.2015.05.002 - describes Drop-seq. - Klein et al., Droplet barcoding for single-cell transcriptomics applied to embryonic stem cells , 2015. DOI:10.1016/j.cell.2015.04.044 - descibes inDrops. Both of the methods makes use of developments in microfluidics published in: - Song, Chen, Ismagilov, Reactions in droplets in microfluidic channels , 2006. DOI:10.1002/anie.200601554 - Guo, Rotem, Heyman and Weitz, Droplet microfluidics for high-throughput biological assays , 2012. DOI:10.1039/C2LC21147E Overview \u00b6 An overview of how a droplet based scRNA-seq method works is illustrated in a figure from the Drop-seq Macosko et al. 2015 paper: A microfluidic device is used to generate an emulsion, which consists of aqueous droplets in oil. The droplets are used to encapsulate cells, beads and reagents. In other words, each droplet is a \"mini laboratory\" in which the RNA from a single-cell can be captured and prepared for identification. Thus, the consistuent parts are as follows: an emulsion (white circles containing beads and cells on the right hand-side of the figure). dissociated cells (depicted as odd-shaped colored objects in the figure). beads (flowing in from the left hand side of the figure). Emulsions \u00b6 The foundation of droplet based single-cell RNA-seq methods are mono-dispersed emulsions . Mono-dispersed refers to the requirements that droplets are of (near) uniform size. Mono-dispersed emulsions can be generated with a microfluidic device, as shown below. The droplets are being \"pinched off\" at the junction, and one can see a polystyrene bead being captured in one droplet, while others are empty. The movie is from the McCarolll Drop-seq tutorial courtesy of Patrick Stumpf, Matthew Rose-Zerilli, Rosanna Smith, Martin Fischlechner & Jonathan West at the Centre for Hybrid Biodevices & Cancer Sciences Unit at the University of Southampton. Beads \u00b6 The figure above, reproduce from Klein et al. 2015, shows the procedure used to make hydrogel beads for inDrops. Every bead contains the same barcode sequence, while the barcode sequences on two different beads are distinct. The barcode and UMI structure for a variety of technologies is viewable in a compilation by Xi Chen. Single cell suspensions \u00b6 In order to assay the transcriptomes of individual cells with droplet-based single-cell RNA-seq technologies, it is necessary to first dissociate tissue. Procedures for tissue dissociation are varied, and highly dependent on the organism, type of tissue, and many other factors. Protocols may be be enzymatic, but can also utilize mechanical dissociators. The talk below provides an introduction to tissue handling and dissociation. 1 2 3 #@title Tissue handling and dissociation from IPython.display import HTML HTML('<iframe width=\"882\" height=\"496\" src=\"https://www.youtube.com/embed/ARozvI4AbS8\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>') Statistics of beads & cells in droplets \u00b6 The binomial distribution \u00b6 An understanding of droplet-based single-cell RNA-seq requires consideration of the statistics describing the capture of cells and beads in droplets. Suppose that in an experiment multiple droplets have been formed, and focus on one of the droplets. Assume that the probability that any single one of $n$ cells were captured inside it is $p$. We can calculate the probability that $k$ cells have been captured in the droplet as follows: $$ \\mathbb{P}({\\mbox Droplet\\ contains\\ k\\ cells}) = \\binom{n}{k}p^k(1-p)^{n-k}.$$ The expected number of cells in the droplet is $$\\lambda := \\sum_{k=0}^n k \\binom{n}{k}p^k(1-p)^{n-k} = n \\cdot p.$$ We plot this distribution on number of cells in a droplet below. It is called the Binomial distribution and has two parameters: $n$ and $p$. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 #@title Binomial distribution { run: \"auto\" } n = 10#@param {type:\"integer\"} p = 0.02 #@param {type:\"slider\", min:0, max:1, step:0.01} fig, ax = plt.subplots(figsize=(7, 4)) s = 10 x = np.arange(s) y = binom.pmf(x,n,p) ax.bar(x, y, color=\"k\", label=\"Binomial n, p = ({}, {})\".format(n,p)) ax.set_xlabel(\"Number of Trials\") ax.set_ylabel(\"Probability\") ax.set_xticks(x) ax.legend() plt.show() With $n=10$ and $p=0.02$, it's quite probable that the droplet is empty, and while possible that it contains one cell, unlikely that it has 2 or more. This is a good regime for a single-cell experiment; we will see that it is problematic if two cells are captured in a single droplet. Empty droplets are not problematic in the sense that they will not lead to data, and can therefore be ignored. The Poisson distribution \u00b6 The Binomial distribution can be difficult to work with in practice. Suppose, for example, that $n=1000$ and $p=0.002$. Suppose that we are interested in the probability of seeing 431 cells in a droplet. This probability is given by $$\\binom{1000}{421}0.02^{421}(1-0.02)^{1000-431},$$ which is evidently a difficult number to calculate exactly. A practical alternative to the binmomial is the Poisson distribution. The Poisson distribution has one parameter, and its support is the non-negative integers. A random variable $X$ is Poisson distributed if $$\\mathbb{P}(X=k)\\quad = \\quad \\frac{e^{-\\lambda}\\lambda^k}{k!}.$$ The Poisson limit theorem states that if $p_n$ is a sequence of real numbers in $[0,1]$ with the sequence $np_n$ converging to to a finite limit $\\lambda$, then $${\\mbox lim}_{n \\rightarrow \\infty} \\binom{n}{k}p_n^{k}(1-p_n)^{n-k} = e^{-\\lambda}\\frac{\\lambda^k}{k!}.$$ Thus, the Poisson distribution serves as a useful, tractable distribution to work with in lieu of the Binomial distribution for large $n$ and small $p$. The histogram below can be used to explore the Poisson and its relationship to the binomial 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 #@title Binomial - Poisson comparison { run: \"auto\" } n = 10#@param {type:\"integer\"} p = 0.02 #@param {type:\"slider\", min:0, max:1, step:0.01} s = 10 lambda_param = n*p fig, ax = plt.subplots(figsize=(14, 4), ncols=2) x = np.arange(s) y = poisson.pmf(x, lambda_param) ax[0].bar(x, y, color=\"k\", label=\"Binomial n, p = ({}, {})\".format(n,p)) ax[0].set_xlabel(\"Number of Trials\") ax[0].set_ylabel(\"Probability\") ax[0].set_xticks(x) ax[0].legend() x = np.arange(s) y = binom.pmf(x,n,p) ax[1].bar(x, y, color=\"k\", label=\"Poisson $\\lambda$={}\".format(lambda_param)) ax[1].set_xlabel(\"Number of Trials\") ax[1].set_ylabel(\"Probability\") ax[1].set_xticks(x) ax[1].legend() plt.show() We therefore posit that $$ \\mathbb{P}({\\mbox Droplet\\ contains\\ k\\ cells}) = \\frac{e^{-\\lambda}\\lambda^k}{k!}$$ and $$ \\mathbb{P}({\\mbox Droplet\\ contains\\ j\\ beads}) = \\frac{e^{-\\mu}\\mu^j}{j!}.$$ Droplet tuning \u00b6 Cell capture and bead overload \u00b6 The cell capture rate is the probability that a droplet has at least one bead, and is given by $1-e^{-\\mu}$. The bead overload rate is the rate at which captured single cells are associated with two or more different barcodes, which will happen when multiple beads are loaded into a droplet with one cell. The probability this happens is $$\\frac{1-e^{-\\mu}-\\mu e^{-\\mu}}{1-e^{-\\mu}}.$$ This leads to a tradeoff, as shown below. 1 2 3 4 5 6 7 8 9 10 11 12 13 #@title Tradeoff { run: \"auto\" } fig, ax = plt.subplots(figsize=(5,5)) mu = np.arange(0, 10, 0.1) x = 1 - np.exp(-mu) y = (1 - np.exp(-mu)-mu*np.exp(-mu))/(1-np.exp(-mu)) ax.plot(x, y, color='k') ax.set_xlabel(\"Cell capture rate\") ax.set_ylabel(\"Bead overload rate\") plt.show() Sub-Poisson loading \u00b6 In order to circumvent the limit posed by a Poisson process for beads in droplets, the inDrops method uses tightly packed hydrogel beads that can be injected into droplets without loss. This approach, which leads to \" sub-Poisson loading \" is also used by 10X Genomics, and allows for increased capture rate. The difference is shown in two videos from the Abate lab linked to below. The first video, shows beads loaded being loaded in droplets with Poisson statistics: 1 2 #@title Poisson loading HTML('<iframe width=\"688\" height=\"387\" src=\"https://www.youtube.com/embed/usK71SG30t0?autoplay=1&loop=1&playlist=usK71SG30t0\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>') The next video shows sub-Poisson loading with hydrogel beads. In this case the flow rate has been set so that exactly two beads are situated in each droplet. 1 2 #@title Sub-Poisson loading { run: \"auto\" } HTML('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/2q1Lt9DWmRQ?autoplay=1&loop=1&playlist=2q1Lt9DWmRQ\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>') The following shows the types of beads used for different droplet-based scRNA-seq methods, and associated properties: Property Drop-seq inDrops 10x genomics Bead material Polystyrene Hydrogel Hydrogel Loading dynamics Poisson sub-Poisson sub-Poisson Dissolvable No No Yes Barcode release No UV release Chemical release Customizable Demonstrated Not shown Feasible Licensing Open source Open Source Proprietary Availability Beads are sold Commercial Commercial Barcode collisions \u00b6 Barcode collisions arise when two cells are separately encapsulated with beads that happen to contain identical barcodes. For $n$ assayed cells with $m$ barcodes, the barcode collision rate is the expected proportion of assayed cells that did not receive a unique barcode, i.e. $$1-\\frac{\\mathbb{E}[\\mbox{cells with a unique barcode}]}{\\mbox{number of cells}}$$ $$= 1-(1-\\frac{1}{m})^{n-1} \\approx 1-\\left(\\frac{1}{e}\\right)^\\frac{n}{m}.$$ Avoiding barcode collisions requires high barcode diversity, i.e. a small ratio of $\\frac{n}{m}$. 1 2 3 4 5 6 7 8 9 10 11 12 13 #@title Diversity and collisions { run: \"auto\" } fig, ax = plt.subplots(figsize=(5,5)) bc = np.arange(0, 1, 0.01) x = bc y = 1 - np.exp(-bc) ax.plot(x, y, color='k') ax.set_xlabel(\"n/m\") ax.set_ylabel(\"Barcode collision rate\") plt.show() Barcode diversity and length \u00b6 A 1% barcode collision rate requires a barcode diversity of ~1%, i.e. the number of barcodes should be 100 times the number of cells. The number of barcodes from a sequence of length $L$ is $4^L$. Therefore, to assay $n$ cells, the barcode sequence must be of length at least $log_4n+3\\frac{1}{3}$. This is a minimum and does not account for the need to be robust to sequencing errors. Technical doublets \u00b6 Technical doublets arise when two or more cells are captured in a droplet with a single bead. The technical doublet rate is therefore the probability of capturing two or more cells in a droplet given that at least one cell has been captured in a droplet: $\\frac{1-e^{-\\lambda}-\\lambda e^{-\\lambda}}{1-e^{-\\lambda}}$. Note that \"overloading\" a droplet-based single-cell experiment by loading more cells while keeping flow rates constant will increase the number of technical doublets due to an effective increase in $\\lambda$ and also the number of synthetic doublets due to an increase in barcode diversity. The barnyard plot \u00b6 Technical doublet rates can be measured by experiments in which a mixture of cells from two different species are assayed together. For example, if mouse and human cells are pooled prior to single-cell RNA-seq, the resultant reads ought to be assignable to either human or mouse. If a droplet contained a \"mixed\" doublet, i.e. two cells one of which is from human and the other from mouse, it will generate reads some of which can be aligned to mouse, and some to human. An example from a 10X Genomics dataset ( 5k 1:1 mixture of fresh frozen human (HEK293T) and mouse (NIH3T3) cells ) is shown in the plot below, which is called a Barnyard plot in Macosko et al. 2015 . 1 2 3 4 %%capture # Download a matrix of human and mouse !wget http://cf.10xgenomics.com/samples/cell-exp/3.0.0/hgmm_1k_v2/hgmm_1k_v2_filtered_feature_bc_matrix.tar.gz !tar -xvf hgmm_1k_v2_filtered_feature_bc_matrix.tar.gz 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 #@title Human & mouse PBMCs mtx = csr_matrix(mmread(\"/content/filtered_feature_bc_matrix/matrix.mtx.gz\").T) genes = pd.read_csv(\"/content/filtered_feature_bc_matrix/features.tsv.gz\", header=None, names=[\"gene_id\", \"gene_name\", \"extra\"], sep=\"\\t\") cells = pd.read_csv(\"/content/filtered_feature_bc_matrix/barcodes.tsv.gz\", header=None, names=[\"cell_barcode\"], sep=\"\\t\") adata = anndata.AnnData(X=mtx, var=genes, obs=cells) adata.var[\"human\"] = adata.var[\"gene_id\"].str.contains(\"hg19\").values x = (mtx[:,adata.var[\"human\"].values]).sum(axis=1) y = (mtx[:,~adata.var[\"human\"].values]).sum(axis=1) fig, ax = plt.subplots(figsize=(5,5)) x = np.asarray(x).reshape(-1) y = np.asarray(y).reshape(-1) ax.scatter(x, y, color='k') ax.set_xlabel(\"Human UMI counts per cell\") ax.set_ylabel(\"Mouse UMI counts per cell\") ax.xaxis.set_major_formatter(mpl.ticker.StrMethodFormatter('{x:,.0f}')) ax.yaxis.set_major_formatter(mpl.ticker.StrMethodFormatter('{x:,.0f}')) plt.show() THe plot shows that there are only 7 doublets out of 5,000 cells in this experiment. This is an unusually small number and atypical of most experiments, where doublet rates are between 5%--15% (see DePasquale et al. 2018 ); perhaps the 5k human mouse PBMC dataset data is articularly \"clean\" as it is an advertisement distributed by 10X Genomics. Bloom's correction \u00b6 The 7 doublets identifiable by eye in the plot above are all mixed doublets , i.e. they contain one human and one mouse cell. However doublets may consist of two mouse cells, or two human cells. If the number of droplets containing at least one human cells is $n_1$, the number containing at least one mouse cell is $n_2$, and the number of mixed doublets is $n_{1,2}$, then an estimate for the actual doublet rate can be obtained from the calculation below ( Bloom 2018 ): Given $n_1, n_2$ and $n_{1,2}$ as described above (note that $n_1$ is the number of cells on the x axis + the number of mixed doublets and $n_2$ is the number of cells on the y axis + the number of mixed doublets), then in expectation $$\\frac{n_1}{N} \\cdot \\frac{n_2}{N} = \\frac{n_{1,2}}{N}, $$ where $N$ is the total number of droplets. From this we see that $$ \\hat{N} = \\frac{n_1 \\cdot n_2}{n_{1,2}}.$$ This is the maximum likelihood Lincoln-Petersen estimator for population size from mark and recapture. Let $\\mu_1$ nad $\\mu_2$ be the Poisson rates for the respective types of cells, i.e. the average number of cells of each type per droplet. Then $$ \\hat{\\mu}_1 = -\\mbox{ln } \\left( \\frac{N-n_1}{N} \\right)$$ and $$ \\hat{\\mu}_2 = -\\mbox{ln } \\left( \\frac{N-n_2}{N} \\right).$$ From this the doublet rate $D$ can be estimated as $$\\hat{D} = 1 - \\frac{(\\mu_1+\\mu_2)e^{-\\mu_1+\\mu_2}}{1-e^{-\\mu_1-\\mu_2}}.$$ Biological doublets \u00b6 Biological doublets arise when two cells form a discrete unit that does not break apart during disruption to form a single-cell suspension. Note that biological doublets cannot be detected in barnyard plots. One approach to avoiding biological doublets is to perform single-nuclei RNA-seq. See, e.g. Habib et al., 2017 . However, biological doublets are not necessarily just a technical artifact to be avoided. Halpern et al., 2018 utilizes biological doublets of hepatocytes and liver endothelial cells to assign tissue coordinates to liver endothelial cells via imputation from their hepatocyte partners. Unique Molecular Identifiers \u00b6 The number of distinct UMIs on a bead in a droplet is at most $4^L$ where $L$ is the number of UMI bases. For example, for 10X Genomics v2 technology $L=10$ and for 10X Genomics v3 technology $L=12$. Melsted, Booeshaghi et al. 2019 show how to estimate the number of the actual distinct UMIs on each bead for which data is obtained in a scRNA-seq experiment. Summary \u00b6 Selection of a single-cell RNA-seq method requires choosing among many tradeoffs that reflect the underlying technologies. The table below, from From Zhang et al. 2019. DOI:10.1016/j.molcel.2018.10.020 , summarizes the three most popular droplet-based single-cell RNA-seq assays: The generation of single-cell RNA-seq data is just the first step in understanding the transcriptomes cells. To interpret the data reads must be aligned or pseudoaligned, UMIs counted, and large cell x gene matrices examined. The growth in single-cell RNA-seq analysis tools for these tasks has been breathtaking. The graph below, plotted from real-time data downloaded from the scRNA-seq tools database , shows the number of tools published since 2016. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 #@title Growth of single-cell tools { run: \"auto\" } tools = pd.read_csv('https://raw.githubusercontent.com/Oshlack/scRNA-tools/master/database/tools.tsv', sep='\\t') tools[\"Datetime\"] = pd.to_datetime(tools[\"Added\"]) tools = tools.sort_values(\"Added\") tools[\"count\"] = 1 fig, ax = plt.subplots(figsize=(12, 5)) x = tools.Datetime y = tools[\"count\"].groupby(tools.Datetime.dt.time).cumsum() ax.plot(x, y, color=\"k\") ax.set_xlabel(\"Date\") ax.set_ylabel(\"Number of tools\") ax.tick_params(axis='x', rotation=45) plt.show() In fact, the rate of growth of single-cell RNA-seq tools is similar to that of single-cell RNA-seq studies : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 #@title scRNA-seq tools vs. studies linear regression date_papers = papers.groupby(\"Datetime\")[\"count\"].sum() date_tools = tools.groupby(\"Datetime\")[\"count\"].sum() dates = pd.date_range(start='7/26/2002', end='01/01/2025') combined = pd.DataFrame(index=dates) combined[\"tool_counts\"] = combined.index.map(date_tools) combined[\"paper_counts\"] = combined.index.map(date_papers) combined = combined.fillna(0) combined[\"Datetime\"] = combined.index.values fig, ax = plt.subplots(figsize=(5,5)) x = combined[\"paper_counts\"].groupby(combined.Datetime.dt.time).cumsum() y = combined[\"tool_counts\"].groupby(combined.Datetime.dt.time).cumsum() ax.scatter(x, y, color=\"k\") regr = linear_model.LinearRegression() x = x.values[:, np.newaxis] regr.fit(x, y.values) xx = np.linspace(0, max(x), 200) yy = regr.intercept_ + regr.coef_*xx ax.plot(xx, yy, color=\"r\", label=f\"{regr.intercept_:,.2f} + {regr.coef_[0]:,.2f}*x\") lims = [np.min([ax.get_xlim(), ax.get_ylim()]), # min of both axes np.max([ax.get_xlim(), ax.get_ylim()])] # max of both axes ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0) ax.set_aspect('equal') ax.set_xlim(lims) ax.set_ylim(lims) ax.set_xlabel(\"Cumulative Papers\") ax.set_ylabel(\"Cumulative Tools\") ax.legend() plt.show() Next step: to learn how to analyze single-cell RNA-seq data, visit the kallistobus.tools site tutorials site and explore the \"Introduction 1: pre-processing and quality control\" notebook in Python or R . Feedback : please report any issues, or submit pull requests for improvements, in the Github repository where this notebook is located .","title":"Test2"},{"location":"tutorials/test2/#an-introduction-to-single-cell-rna-seq","text":"","title":"An introduction to single-cell RNA-seq"},{"location":"tutorials/test2/#written-by-sina-booeshaghi-and-lior-pachter-based-on-material-taught-in-caltech-course-bibecs183-by-lior-pachter-and-matt-thomson-with-contributions-from-sina-booeshaghi-lambda-lu-jialong-jiang-eduardo-beltrame-jase-gehring-ingileif-hallgrimsdottir-and-valentine-svensson","text":"","title":"Written by Sina Booeshaghi and Lior Pachter. Based on material taught in Caltech course Bi/BE/CS183 by Lior Pachter and Matt Thomson, with contributions from Sina Booeshaghi, Lambda Lu, Jialong Jiang, Eduardo Beltrame, Jase Gehring, Ingileif Hallgr\u00edmsd\u00f3ttir and Valentine Svensson."},{"location":"tutorials/test2/#division-of-biology-and-biological-engineering-california-institute-of-technology","text":"The rapid development of single-cell genomics methods starting in 2009 has created unprecedented opportunity for highly resolved measurements of cellular states. Among such methods, single-cell RNA-seq (scRNA-seq) is having a profound impact on biology. Here we introduce some of the key concepts of single-cell RNA-seq technologies, with a focus on droplet based methods. To learn how to pre-process and analyze single-cell RNA-seq explore the following Google Colab notebooks that explain how to go from reads to results: Pre-processing and quality control [ Python , R ] Getting started with analysis [ Python , R ] Building and annotating an atlas [ Python , R ] The kallistobus.tools tutorials site has a extensive list of tutorials and vignettes on single-cell RNA-seq.","title":"*Division of Biology and Biological Engineering, California Institute of Technology"},{"location":"tutorials/test2/#setup","text":"This notebook is a \"living document\". It downloads data and performs computations. As such it requires the installation of some python packages, which are installed with the commands below. In addition to running on Google Colab, the notebook can be downloaded and run locally on any machine which has python3 installed. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 #@title Install packages %%capture !pip install matplotlib !pip install scikit-learn !pip install numpy !pip install scipy !pip install anndata import numpy as np import matplotlib.cm as cm import matplotlib.pyplot as plt import matplotlib.colors as mplcol import matplotlib.font_manager import matplotlib as mpl import pandas as pd import io import anndata from scipy.stats import binom from scipy.stats import poisson from scipy.sparse import csr_matrix from scipy.io import mmread from sklearn import linear_model from IPython.display import HTML from mizani.breaks import date_breaks from mizani.formatters import date_format # Only pandas >= v0.25.0 supports column names with spaces in querys import plotnine as p import requests import warnings import colorsys warnings.filterwarnings(\"ignore\") # plotnine has a lot of MatplotlibDeprecationWarning's import seaborn as sns sns.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 2.5}) fsize=20 plt.rcParams.update({'font.size': fsize}) %config InlineBackend.figure_format = 'retina'","title":"Setup"},{"location":"tutorials/test2/#motivation","text":"The goal of single-cell transcriptomics is to measure the transcriptional states of large numbers of cells simultaneously. The input to a scRNA-seq method is a collection of cells, possibly from intact tissue, or in dissociated form. Formally, the desired output is a transcripts x cells or genes x cells matrix that describes, for each cell, the abundance of its constituent transcripts or genes. More generally, single-cell genomics methods seek to measure not just transcriptional state, but other modalities in cells, e.g. protein abundances, epigenetic states, cellular morphology, etc. The ideal single-cell technology should thus: Be universal in terms of cell size, type and state. Perform in situ measurements. Have no minimum input requirements. Assay every cell, i.e. have a 100% capture rate . Detect every transcript in every cell, i.e. have 100% sensitivity . Identify individual transcripts by their full-length sequence . Assign transcripts correctly to cells, e.g. no doublets . Be compatible with additional multimodal measurements . Be cost effective per cell. Be easy to use . Be open source so that it is transparent, and results from it reproducible. There is no method satisfying all of these requirements, however progress has been rapid. The development of single-cell RNA-seq technologies and their adoption by biologists, has been remarkable. Svensson et al. 2019 describes a database of articles which present single-cell RNA-seq experiments, and the graph below, rendered from the current version of the database , makes clear the exponential growth in single-cell transcriptomics: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 #@title Growth of single-cell RNA-seq df = pd.read_csv('http://nxn.se/single-cell-studies/data.tsv', sep='\\t') # converts string to date format, can only be run once! df['Date'] = pd.to_datetime(df['Date'], format='%Y%m%d') # converts string of reported cells total to float, can only be run once! df['Reported cells total'] = df['Reported cells total'].str.replace(',', '').map(float) # plot number of studies over time fig, ax = plt.subplots(figsize=(12, 5)) papers = pd.read_csv('http://nxn.se/single-cell-studies/data.tsv', sep='\\t') papers['Datetime'] = pd.to_datetime(papers['Date'], format='%Y%m%d') papers = papers.sort_values(\"Date\") papers[\"count\"] = 1 x = papers.Datetime y = papers[\"count\"].groupby(papers.Datetime.dt.time).cumsum() ax.plot(x, y, color=\"k\") ax.set_xlabel(\"Date\") ax.set_ylabel(\"Cumulative number of studies\") plt.show() There are many different scRNA-seq technologies in use and under development, but broadly they fall into a few categories - well-based methods (e.g. Fluidigm SMARTer C1, Smart-seq2) - droplet-based methods (e.g. Drop-seq, InDrops, 10X Genomics Chromium) - spatial transcriptomics approaches (e.g. MERFISH, SEQFISH) At the time of initial writing of this document (2019), droplet-based approaches have become popular due to their relative low-cost, easy of use, and scalability. This is evident in a breakdown of articles by technology used: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 #@title Technologies used def tidy_split(df, column, sep='|', keep=False): indexes = list() new_values = list() df = df.dropna(subset=[column]) for i, presplit in enumerate(df[column].astype(str)): values = presplit.split(sep) if keep and len(values) > 1: indexes.append(i) new_values.append(presplit) for value in values: indexes.append(i) new_values.append(value) new_df = df.iloc[indexes, :].copy() new_df[column] = new_values return new_df ts = pd.Timestamp tdf = tidy_split(df, 'Technique', ' & ') t_dict = {k: k for k in tdf['Technique'].value_counts().head(5).index} tdf['Technique'] = tdf['Technique'].map(lambda s: t_dict.get(s, 'Other')) techs = list( tdf['Technique'] .value_counts() .sort_index() .index .difference(['Other']) ) techs.append('Other') tdf['Technique'] = ( pd.Categorical( tdf['Technique'], categories=techs, ordered=True ) ) def desaturate(color, prop): # Check inputs # if not 0 <= prop <= 1: # raise ValueError(\"prop must be between 0 and 1\") # Get rgb tuple rep rgb = mplcol.colorConverter.to_rgb(color) # Convert to hls h, l, s = colorsys.rgb_to_hls(*rgb) # Desaturate the saturation channel # l *= prop l = 0.8 # Convert back to rgb new_color = colorsys.hls_to_rgb(h, l, s) hex_color = '#{:02x}{:02x}{:02x}'.format(*map(lambda c: int(c * 255), new_color)) return hex_color # lighten matplotlib default colors clrs = list(map(lambda c: desaturate(c, 1.2), ['C0', 'C1', 'C2', 'C3', 'C4', 'black'])) #### Plot number of studies per month by technique per_month = ( tdf .groupby('Technique') .resample('1M', on='Date') .count()['DOI'] .reset_index() ) p.options.figure_size = (9, 2) fig = ( p.ggplot( p.aes(x='Date', y='DOI', fill='Technique'), data=per_month.query('Date > @ts(\"20130101T010101\")') ) + p.geom_bar(stat='identity', color='grey') + p.theme_minimal(base_family='DejaVu Sans') + p.scale_x_datetime( breaks=date_breaks('1 years'), labels=date_format('%Y') ) + p.labs(y='Number of studies') + p.scale_fill_manual(clrs) ) fig <ggplot: (-9223363288449985206)> We therefore restrict this exposition to droplet-based technologies.","title":"Motivation"},{"location":"tutorials/test2/#droplet-based-methods","text":"Droplet based single-cell RNA-seq methods were popularized by a pair of papers published concurrently in 2015: - Macosko et al., Highly parallel genome-wide expression profiling of individual cells using nanoliter droplets , 2015. DOI:10.1016/j.cell.2015.05.002 - describes Drop-seq. - Klein et al., Droplet barcoding for single-cell transcriptomics applied to embryonic stem cells , 2015. DOI:10.1016/j.cell.2015.04.044 - descibes inDrops. Both of the methods makes use of developments in microfluidics published in: - Song, Chen, Ismagilov, Reactions in droplets in microfluidic channels , 2006. DOI:10.1002/anie.200601554 - Guo, Rotem, Heyman and Weitz, Droplet microfluidics for high-throughput biological assays , 2012. DOI:10.1039/C2LC21147E","title":"Droplet-based methods"},{"location":"tutorials/test2/#overview","text":"An overview of how a droplet based scRNA-seq method works is illustrated in a figure from the Drop-seq Macosko et al. 2015 paper: A microfluidic device is used to generate an emulsion, which consists of aqueous droplets in oil. The droplets are used to encapsulate cells, beads and reagents. In other words, each droplet is a \"mini laboratory\" in which the RNA from a single-cell can be captured and prepared for identification. Thus, the consistuent parts are as follows: an emulsion (white circles containing beads and cells on the right hand-side of the figure). dissociated cells (depicted as odd-shaped colored objects in the figure). beads (flowing in from the left hand side of the figure).","title":"Overview"},{"location":"tutorials/test2/#emulsions","text":"The foundation of droplet based single-cell RNA-seq methods are mono-dispersed emulsions . Mono-dispersed refers to the requirements that droplets are of (near) uniform size. Mono-dispersed emulsions can be generated with a microfluidic device, as shown below. The droplets are being \"pinched off\" at the junction, and one can see a polystyrene bead being captured in one droplet, while others are empty. The movie is from the McCarolll Drop-seq tutorial courtesy of Patrick Stumpf, Matthew Rose-Zerilli, Rosanna Smith, Martin Fischlechner & Jonathan West at the Centre for Hybrid Biodevices & Cancer Sciences Unit at the University of Southampton.","title":"Emulsions"},{"location":"tutorials/test2/#beads","text":"The figure above, reproduce from Klein et al. 2015, shows the procedure used to make hydrogel beads for inDrops. Every bead contains the same barcode sequence, while the barcode sequences on two different beads are distinct. The barcode and UMI structure for a variety of technologies is viewable in a compilation by Xi Chen.","title":"Beads"},{"location":"tutorials/test2/#single-cell-suspensions","text":"In order to assay the transcriptomes of individual cells with droplet-based single-cell RNA-seq technologies, it is necessary to first dissociate tissue. Procedures for tissue dissociation are varied, and highly dependent on the organism, type of tissue, and many other factors. Protocols may be be enzymatic, but can also utilize mechanical dissociators. The talk below provides an introduction to tissue handling and dissociation. 1 2 3 #@title Tissue handling and dissociation from IPython.display import HTML HTML('<iframe width=\"882\" height=\"496\" src=\"https://www.youtube.com/embed/ARozvI4AbS8\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>')","title":"Single cell suspensions"},{"location":"tutorials/test2/#statistics-of-beads-cells-in-droplets","text":"","title":"Statistics of beads &amp; cells in droplets"},{"location":"tutorials/test2/#the-binomial-distribution","text":"An understanding of droplet-based single-cell RNA-seq requires consideration of the statistics describing the capture of cells and beads in droplets. Suppose that in an experiment multiple droplets have been formed, and focus on one of the droplets. Assume that the probability that any single one of $n$ cells were captured inside it is $p$. We can calculate the probability that $k$ cells have been captured in the droplet as follows: $$ \\mathbb{P}({\\mbox Droplet\\ contains\\ k\\ cells}) = \\binom{n}{k}p^k(1-p)^{n-k}.$$ The expected number of cells in the droplet is $$\\lambda := \\sum_{k=0}^n k \\binom{n}{k}p^k(1-p)^{n-k} = n \\cdot p.$$ We plot this distribution on number of cells in a droplet below. It is called the Binomial distribution and has two parameters: $n$ and $p$. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 #@title Binomial distribution { run: \"auto\" } n = 10#@param {type:\"integer\"} p = 0.02 #@param {type:\"slider\", min:0, max:1, step:0.01} fig, ax = plt.subplots(figsize=(7, 4)) s = 10 x = np.arange(s) y = binom.pmf(x,n,p) ax.bar(x, y, color=\"k\", label=\"Binomial n, p = ({}, {})\".format(n,p)) ax.set_xlabel(\"Number of Trials\") ax.set_ylabel(\"Probability\") ax.set_xticks(x) ax.legend() plt.show() With $n=10$ and $p=0.02$, it's quite probable that the droplet is empty, and while possible that it contains one cell, unlikely that it has 2 or more. This is a good regime for a single-cell experiment; we will see that it is problematic if two cells are captured in a single droplet. Empty droplets are not problematic in the sense that they will not lead to data, and can therefore be ignored.","title":"The binomial distribution"},{"location":"tutorials/test2/#the-poisson-distribution","text":"The Binomial distribution can be difficult to work with in practice. Suppose, for example, that $n=1000$ and $p=0.002$. Suppose that we are interested in the probability of seeing 431 cells in a droplet. This probability is given by $$\\binom{1000}{421}0.02^{421}(1-0.02)^{1000-431},$$ which is evidently a difficult number to calculate exactly. A practical alternative to the binmomial is the Poisson distribution. The Poisson distribution has one parameter, and its support is the non-negative integers. A random variable $X$ is Poisson distributed if $$\\mathbb{P}(X=k)\\quad = \\quad \\frac{e^{-\\lambda}\\lambda^k}{k!}.$$ The Poisson limit theorem states that if $p_n$ is a sequence of real numbers in $[0,1]$ with the sequence $np_n$ converging to to a finite limit $\\lambda$, then $${\\mbox lim}_{n \\rightarrow \\infty} \\binom{n}{k}p_n^{k}(1-p_n)^{n-k} = e^{-\\lambda}\\frac{\\lambda^k}{k!}.$$ Thus, the Poisson distribution serves as a useful, tractable distribution to work with in lieu of the Binomial distribution for large $n$ and small $p$. The histogram below can be used to explore the Poisson and its relationship to the binomial 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 #@title Binomial - Poisson comparison { run: \"auto\" } n = 10#@param {type:\"integer\"} p = 0.02 #@param {type:\"slider\", min:0, max:1, step:0.01} s = 10 lambda_param = n*p fig, ax = plt.subplots(figsize=(14, 4), ncols=2) x = np.arange(s) y = poisson.pmf(x, lambda_param) ax[0].bar(x, y, color=\"k\", label=\"Binomial n, p = ({}, {})\".format(n,p)) ax[0].set_xlabel(\"Number of Trials\") ax[0].set_ylabel(\"Probability\") ax[0].set_xticks(x) ax[0].legend() x = np.arange(s) y = binom.pmf(x,n,p) ax[1].bar(x, y, color=\"k\", label=\"Poisson $\\lambda$={}\".format(lambda_param)) ax[1].set_xlabel(\"Number of Trials\") ax[1].set_ylabel(\"Probability\") ax[1].set_xticks(x) ax[1].legend() plt.show() We therefore posit that $$ \\mathbb{P}({\\mbox Droplet\\ contains\\ k\\ cells}) = \\frac{e^{-\\lambda}\\lambda^k}{k!}$$ and $$ \\mathbb{P}({\\mbox Droplet\\ contains\\ j\\ beads}) = \\frac{e^{-\\mu}\\mu^j}{j!}.$$","title":"The Poisson distribution"},{"location":"tutorials/test2/#droplet-tuning","text":"","title":"Droplet tuning"},{"location":"tutorials/test2/#cell-capture-and-bead-overload","text":"The cell capture rate is the probability that a droplet has at least one bead, and is given by $1-e^{-\\mu}$. The bead overload rate is the rate at which captured single cells are associated with two or more different barcodes, which will happen when multiple beads are loaded into a droplet with one cell. The probability this happens is $$\\frac{1-e^{-\\mu}-\\mu e^{-\\mu}}{1-e^{-\\mu}}.$$ This leads to a tradeoff, as shown below. 1 2 3 4 5 6 7 8 9 10 11 12 13 #@title Tradeoff { run: \"auto\" } fig, ax = plt.subplots(figsize=(5,5)) mu = np.arange(0, 10, 0.1) x = 1 - np.exp(-mu) y = (1 - np.exp(-mu)-mu*np.exp(-mu))/(1-np.exp(-mu)) ax.plot(x, y, color='k') ax.set_xlabel(\"Cell capture rate\") ax.set_ylabel(\"Bead overload rate\") plt.show()","title":"Cell capture and bead overload"},{"location":"tutorials/test2/#sub-poisson-loading","text":"In order to circumvent the limit posed by a Poisson process for beads in droplets, the inDrops method uses tightly packed hydrogel beads that can be injected into droplets without loss. This approach, which leads to \" sub-Poisson loading \" is also used by 10X Genomics, and allows for increased capture rate. The difference is shown in two videos from the Abate lab linked to below. The first video, shows beads loaded being loaded in droplets with Poisson statistics: 1 2 #@title Poisson loading HTML('<iframe width=\"688\" height=\"387\" src=\"https://www.youtube.com/embed/usK71SG30t0?autoplay=1&loop=1&playlist=usK71SG30t0\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>') The next video shows sub-Poisson loading with hydrogel beads. In this case the flow rate has been set so that exactly two beads are situated in each droplet. 1 2 #@title Sub-Poisson loading { run: \"auto\" } HTML('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/2q1Lt9DWmRQ?autoplay=1&loop=1&playlist=2q1Lt9DWmRQ\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>') The following shows the types of beads used for different droplet-based scRNA-seq methods, and associated properties: Property Drop-seq inDrops 10x genomics Bead material Polystyrene Hydrogel Hydrogel Loading dynamics Poisson sub-Poisson sub-Poisson Dissolvable No No Yes Barcode release No UV release Chemical release Customizable Demonstrated Not shown Feasible Licensing Open source Open Source Proprietary Availability Beads are sold Commercial Commercial","title":"Sub-Poisson loading"},{"location":"tutorials/test2/#barcode-collisions","text":"Barcode collisions arise when two cells are separately encapsulated with beads that happen to contain identical barcodes. For $n$ assayed cells with $m$ barcodes, the barcode collision rate is the expected proportion of assayed cells that did not receive a unique barcode, i.e. $$1-\\frac{\\mathbb{E}[\\mbox{cells with a unique barcode}]}{\\mbox{number of cells}}$$ $$= 1-(1-\\frac{1}{m})^{n-1} \\approx 1-\\left(\\frac{1}{e}\\right)^\\frac{n}{m}.$$ Avoiding barcode collisions requires high barcode diversity, i.e. a small ratio of $\\frac{n}{m}$. 1 2 3 4 5 6 7 8 9 10 11 12 13 #@title Diversity and collisions { run: \"auto\" } fig, ax = plt.subplots(figsize=(5,5)) bc = np.arange(0, 1, 0.01) x = bc y = 1 - np.exp(-bc) ax.plot(x, y, color='k') ax.set_xlabel(\"n/m\") ax.set_ylabel(\"Barcode collision rate\") plt.show()","title":"Barcode collisions"},{"location":"tutorials/test2/#barcode-diversity-and-length","text":"A 1% barcode collision rate requires a barcode diversity of ~1%, i.e. the number of barcodes should be 100 times the number of cells. The number of barcodes from a sequence of length $L$ is $4^L$. Therefore, to assay $n$ cells, the barcode sequence must be of length at least $log_4n+3\\frac{1}{3}$. This is a minimum and does not account for the need to be robust to sequencing errors.","title":"Barcode diversity and length"},{"location":"tutorials/test2/#technical-doublets","text":"Technical doublets arise when two or more cells are captured in a droplet with a single bead. The technical doublet rate is therefore the probability of capturing two or more cells in a droplet given that at least one cell has been captured in a droplet: $\\frac{1-e^{-\\lambda}-\\lambda e^{-\\lambda}}{1-e^{-\\lambda}}$. Note that \"overloading\" a droplet-based single-cell experiment by loading more cells while keeping flow rates constant will increase the number of technical doublets due to an effective increase in $\\lambda$ and also the number of synthetic doublets due to an increase in barcode diversity.","title":"Technical doublets"},{"location":"tutorials/test2/#the-barnyard-plot","text":"Technical doublet rates can be measured by experiments in which a mixture of cells from two different species are assayed together. For example, if mouse and human cells are pooled prior to single-cell RNA-seq, the resultant reads ought to be assignable to either human or mouse. If a droplet contained a \"mixed\" doublet, i.e. two cells one of which is from human and the other from mouse, it will generate reads some of which can be aligned to mouse, and some to human. An example from a 10X Genomics dataset ( 5k 1:1 mixture of fresh frozen human (HEK293T) and mouse (NIH3T3) cells ) is shown in the plot below, which is called a Barnyard plot in Macosko et al. 2015 . 1 2 3 4 %%capture # Download a matrix of human and mouse !wget http://cf.10xgenomics.com/samples/cell-exp/3.0.0/hgmm_1k_v2/hgmm_1k_v2_filtered_feature_bc_matrix.tar.gz !tar -xvf hgmm_1k_v2_filtered_feature_bc_matrix.tar.gz 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 #@title Human & mouse PBMCs mtx = csr_matrix(mmread(\"/content/filtered_feature_bc_matrix/matrix.mtx.gz\").T) genes = pd.read_csv(\"/content/filtered_feature_bc_matrix/features.tsv.gz\", header=None, names=[\"gene_id\", \"gene_name\", \"extra\"], sep=\"\\t\") cells = pd.read_csv(\"/content/filtered_feature_bc_matrix/barcodes.tsv.gz\", header=None, names=[\"cell_barcode\"], sep=\"\\t\") adata = anndata.AnnData(X=mtx, var=genes, obs=cells) adata.var[\"human\"] = adata.var[\"gene_id\"].str.contains(\"hg19\").values x = (mtx[:,adata.var[\"human\"].values]).sum(axis=1) y = (mtx[:,~adata.var[\"human\"].values]).sum(axis=1) fig, ax = plt.subplots(figsize=(5,5)) x = np.asarray(x).reshape(-1) y = np.asarray(y).reshape(-1) ax.scatter(x, y, color='k') ax.set_xlabel(\"Human UMI counts per cell\") ax.set_ylabel(\"Mouse UMI counts per cell\") ax.xaxis.set_major_formatter(mpl.ticker.StrMethodFormatter('{x:,.0f}')) ax.yaxis.set_major_formatter(mpl.ticker.StrMethodFormatter('{x:,.0f}')) plt.show() THe plot shows that there are only 7 doublets out of 5,000 cells in this experiment. This is an unusually small number and atypical of most experiments, where doublet rates are between 5%--15% (see DePasquale et al. 2018 ); perhaps the 5k human mouse PBMC dataset data is articularly \"clean\" as it is an advertisement distributed by 10X Genomics.","title":"The barnyard plot"},{"location":"tutorials/test2/#blooms-correction","text":"The 7 doublets identifiable by eye in the plot above are all mixed doublets , i.e. they contain one human and one mouse cell. However doublets may consist of two mouse cells, or two human cells. If the number of droplets containing at least one human cells is $n_1$, the number containing at least one mouse cell is $n_2$, and the number of mixed doublets is $n_{1,2}$, then an estimate for the actual doublet rate can be obtained from the calculation below ( Bloom 2018 ): Given $n_1, n_2$ and $n_{1,2}$ as described above (note that $n_1$ is the number of cells on the x axis + the number of mixed doublets and $n_2$ is the number of cells on the y axis + the number of mixed doublets), then in expectation $$\\frac{n_1}{N} \\cdot \\frac{n_2}{N} = \\frac{n_{1,2}}{N}, $$ where $N$ is the total number of droplets. From this we see that $$ \\hat{N} = \\frac{n_1 \\cdot n_2}{n_{1,2}}.$$ This is the maximum likelihood Lincoln-Petersen estimator for population size from mark and recapture. Let $\\mu_1$ nad $\\mu_2$ be the Poisson rates for the respective types of cells, i.e. the average number of cells of each type per droplet. Then $$ \\hat{\\mu}_1 = -\\mbox{ln } \\left( \\frac{N-n_1}{N} \\right)$$ and $$ \\hat{\\mu}_2 = -\\mbox{ln } \\left( \\frac{N-n_2}{N} \\right).$$ From this the doublet rate $D$ can be estimated as $$\\hat{D} = 1 - \\frac{(\\mu_1+\\mu_2)e^{-\\mu_1+\\mu_2}}{1-e^{-\\mu_1-\\mu_2}}.$$","title":"Bloom's correction"},{"location":"tutorials/test2/#biological-doublets","text":"Biological doublets arise when two cells form a discrete unit that does not break apart during disruption to form a single-cell suspension. Note that biological doublets cannot be detected in barnyard plots. One approach to avoiding biological doublets is to perform single-nuclei RNA-seq. See, e.g. Habib et al., 2017 . However, biological doublets are not necessarily just a technical artifact to be avoided. Halpern et al., 2018 utilizes biological doublets of hepatocytes and liver endothelial cells to assign tissue coordinates to liver endothelial cells via imputation from their hepatocyte partners.","title":"Biological doublets"},{"location":"tutorials/test2/#unique-molecular-identifiers","text":"The number of distinct UMIs on a bead in a droplet is at most $4^L$ where $L$ is the number of UMI bases. For example, for 10X Genomics v2 technology $L=10$ and for 10X Genomics v3 technology $L=12$. Melsted, Booeshaghi et al. 2019 show how to estimate the number of the actual distinct UMIs on each bead for which data is obtained in a scRNA-seq experiment.","title":"Unique Molecular Identifiers"},{"location":"tutorials/test2/#summary","text":"Selection of a single-cell RNA-seq method requires choosing among many tradeoffs that reflect the underlying technologies. The table below, from From Zhang et al. 2019. DOI:10.1016/j.molcel.2018.10.020 , summarizes the three most popular droplet-based single-cell RNA-seq assays: The generation of single-cell RNA-seq data is just the first step in understanding the transcriptomes cells. To interpret the data reads must be aligned or pseudoaligned, UMIs counted, and large cell x gene matrices examined. The growth in single-cell RNA-seq analysis tools for these tasks has been breathtaking. The graph below, plotted from real-time data downloaded from the scRNA-seq tools database , shows the number of tools published since 2016. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 #@title Growth of single-cell tools { run: \"auto\" } tools = pd.read_csv('https://raw.githubusercontent.com/Oshlack/scRNA-tools/master/database/tools.tsv', sep='\\t') tools[\"Datetime\"] = pd.to_datetime(tools[\"Added\"]) tools = tools.sort_values(\"Added\") tools[\"count\"] = 1 fig, ax = plt.subplots(figsize=(12, 5)) x = tools.Datetime y = tools[\"count\"].groupby(tools.Datetime.dt.time).cumsum() ax.plot(x, y, color=\"k\") ax.set_xlabel(\"Date\") ax.set_ylabel(\"Number of tools\") ax.tick_params(axis='x', rotation=45) plt.show() In fact, the rate of growth of single-cell RNA-seq tools is similar to that of single-cell RNA-seq studies : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 #@title scRNA-seq tools vs. studies linear regression date_papers = papers.groupby(\"Datetime\")[\"count\"].sum() date_tools = tools.groupby(\"Datetime\")[\"count\"].sum() dates = pd.date_range(start='7/26/2002', end='01/01/2025') combined = pd.DataFrame(index=dates) combined[\"tool_counts\"] = combined.index.map(date_tools) combined[\"paper_counts\"] = combined.index.map(date_papers) combined = combined.fillna(0) combined[\"Datetime\"] = combined.index.values fig, ax = plt.subplots(figsize=(5,5)) x = combined[\"paper_counts\"].groupby(combined.Datetime.dt.time).cumsum() y = combined[\"tool_counts\"].groupby(combined.Datetime.dt.time).cumsum() ax.scatter(x, y, color=\"k\") regr = linear_model.LinearRegression() x = x.values[:, np.newaxis] regr.fit(x, y.values) xx = np.linspace(0, max(x), 200) yy = regr.intercept_ + regr.coef_*xx ax.plot(xx, yy, color=\"r\", label=f\"{regr.intercept_:,.2f} + {regr.coef_[0]:,.2f}*x\") lims = [np.min([ax.get_xlim(), ax.get_ylim()]), # min of both axes np.max([ax.get_xlim(), ax.get_ylim()])] # max of both axes ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0) ax.set_aspect('equal') ax.set_xlim(lims) ax.set_ylim(lims) ax.set_xlabel(\"Cumulative Papers\") ax.set_ylabel(\"Cumulative Tools\") ax.legend() plt.show() Next step: to learn how to analyze single-cell RNA-seq data, visit the kallistobus.tools site tutorials site and explore the \"Introduction 1: pre-processing and quality control\" notebook in Python or R . Feedback : please report any issues, or submit pull requests for improvements, in the Github repository where this notebook is located .","title":"Summary"}]}